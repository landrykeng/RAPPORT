import streamlit as st
import pandas as pd
import numpy as np
import os
import io
from datetime import datetime
import zipfile
import base64
import re
from typing import Dict, List, Optional, Tuple

# Imports pour les statistiques
from scipy import stats
from scipy.stats import chi2_contingency, fisher_exact, shapiro, normaltest
from scipy.stats import mannwhitneyu, kruskal, ttest_ind, f_oneway

# Imports pour les graphiques
from streamlit_echarts import st_echarts
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.io as pio

# Imports pour la g√©n√©ration de documents Word
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_ALIGNMENT
from docx.oxml.shared import OxmlElement, qn

# Configuration de la page
st.set_page_config(
    page_title="üìä Analyseur Statistique Pro",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0066cc;
        margin: 1rem 0;
    }
    .metric-container {
        background-color: #f0f8ff;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #0066cc;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
        color: #155724;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
        color: #856404;
    }
    .info-box {
        background-color: #cce7ff;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #99d6ff;
        color: #004080;
    }
    .analysis-container {
        border: 2px solid #e0e0e0;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
        background-color: #fafafa;
    }
    .palette-preview {
        display: flex;
        gap: 5px;
        margin: 5px 0;
    }
    .color-box {
        width: 20px;
        height: 20px;
        border-radius: 3px;
        border: 1px solid #ccc;
    }
</style>
""", unsafe_allow_html=True)

# D√©finition des palettes de couleurs
COLOR_PALETTES = {
    "D√©faut (Verte/Orange)": [
        '#0C752C', '#F15A02', '#DBB300', '#FFEA2B', '#96CEB4', 
        '#FFEAA7', '#DDA0DD', '#98D8C8', '#F7DC6F', '#BB8FCE',
        '#85C1E9', '#F8C471', '#82E0AA', '#F1948A', '#F5B7B1'
    ],
    "Bleus oc√©an": [
        '#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c',
        '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5',
        '#8c564b', '#c49c94', '#e377c2', '#f7b6d3', '#17becf'
    ],
    "Tons chauds": [
        '#d62728', '#ff7f0e', '#ff9896', '#ffbb78', '#e377c2',
        '#f7b6d3', '#bcbd22', '#dbdb8d', '#8c564b', '#c49c94',
        '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#1f77b4'
    ],
    "Pastels doux": [
        '#FFB6C1', '#87CEEB', '#98FB98', '#F0E68C', '#DDA0DD',
        '#FFEAA7', '#96CEB4', '#F8C471', '#85C1E9', '#82E0AA',
        '#F1948A', '#BB8FCE', '#F7DC6F', '#98D8C8', '#F5B7B1'
    ],
    "Tons terreux": [
        '#8B4513', '#CD853F', '#D2691E', '#F4A460', '#DEB887',
        '#BC8F8F', '#F5DEB3', '#D3D3D3', '#A0522D', '#800000',
        '#B22222', '#DC143C', '#FF6347', '#FF4500', '#FF8C00'
    ],
    "Monochrome": [
        '#2F4F4F', '#696969', '#808080', '#A9A9A9', '#C0C0C0',
        '#D3D3D3', '#DCDCDC', '#F5F5F5', '#000000', '#1C1C1C',
        '#363636', '#4F4F4F', '#6B6B6B', '#878787', '#A3A3A3'
    ],
    "Arc-en-ciel": [
        '#FF0000', '#FF7F00', '#FFFF00', '#00FF00', '#0000FF',
        '#4B0082', '#9400D3', '#FF1493', '#00CED1', '#32CD32',
        '#FFD700', '#FF69B4', '#8A2BE2', '#00FA9A', '#FF6347'
    ]
}

# Fonction pour analyser un document de r√©f√©rence
def analyze_reference_document(uploaded_file):
    """Analyse un document de r√©f√©rence pour extraire le contexte"""
    try:
        if uploaded_file.name.endswith('.txt'):
            content = str(uploaded_file.read(), 'utf-8')
        elif uploaded_file.name.endswith('.docx'):
            # Si python-docx est disponible
            try:
                import docx
                doc = docx.Document(uploaded_file)
                content = '\n'.join([paragraph.text for paragraph in doc.paragraphs])
            except ImportError:
                st.warning("python-docx non install√©. Utilisez un fichier .txt")
                return None
        else:
            st.error("Format non support√©. Utilisez .txt ou .docx")
            return None
        
        return content[:2000]  # Limiter √† 2000 caract√®res pour le contexte
    except Exception as e:
        st.error(f"Erreur lors de la lecture du document: {str(e)}")
        return None

# Classe pour g√©n√©rer les commentaires automatiques
class StatisticalCommentator:
    def __init__(self, study_theme: str = "", reference_context: str = ""):
        self.study_theme = study_theme
        self.reference_context = reference_context
        
    def interpret_descriptive_stats(self, stats_dict: Dict, var_name: str, var_type: str = "numeric") -> str:
        """G√©n√®re des commentaires pour les statistiques descriptives"""
        comments = []
        
        if var_type == "numeric":
            moyenne = stats_dict.get('Moyenne', 0)
            mediane = stats_dict.get('M√©diane', 0)
            ecart_type = stats_dict.get('√âcart-type', 0)
            asymetrie = stats_dict.get('Asym√©trie', 0)
            aplatissement = stats_dict.get('Aplatissement', 0)
            missing_pct = stats_dict.get('% Manquantes', 0)
            
            # Commentaire sur la tendance centrale
            if abs(moyenne - mediane) / max(abs(moyenne), abs(mediane), 1) > 0.1:
                if moyenne > mediane:
                    comments.append(f"La variable **{var_name}** pr√©sente une asym√©trie positive (moyenne > m√©diane), "
                                  f"sugg√©rant la pr√©sence de valeurs √©lev√©es qui tirent la distribution vers la droite.")
                else:
                    comments.append(f"La variable **{var_name}** pr√©sente une asym√©trie n√©gative (moyenne < m√©diane), "
                                  f"sugg√©rant la pr√©sence de valeurs faibles qui tirent la distribution vers la gauche.")
            else:
                comments.append(f"La variable **{var_name}** pr√©sente une distribution relativement sym√©trique "
                              f"(moyenne ‚âà m√©diane = {moyenne:.2f}).")
            
            # Commentaire sur la dispersion
            if moyenne != 0:
                cv = (ecart_type / abs(moyenne)) * 100
                if cv < 15:
                    comments.append(f"La dispersion est faible (CV = {cv:.1f}%), indiquant une homog√©n√©it√© des valeurs.")
                elif cv < 30:
                    comments.append(f"La dispersion est mod√©r√©e (CV = {cv:.1f}%), sugg√©rant une variabilit√© normale.")
                else:
                    comments.append(f"La dispersion est √©lev√©e (CV = {cv:.1f}%), r√©v√©lant une forte h√©t√©rog√©n√©it√© des observations.")
            
            # Commentaire sur l'asym√©trie
            if abs(asymetrie) > 1:
                direction = "fortement asym√©trique √† droite" if asymetrie > 0 else "fortement asym√©trique √† gauche"
                comments.append(f"L'indice d'asym√©trie ({asymetrie:.2f}) confirme une distribution {direction}.")
            
            # Commentaire sur l'aplatissement
            if aplatissement > 3:
                comments.append(f"L'aplatissement √©lev√© ({aplatissement:.2f}) indique une distribution leptocurtique "
                              f"avec des queues plus lourdes que la normale.")
            elif aplatissement < -1:
                comments.append(f"L'aplatissement faible ({aplatissement:.2f}) indique une distribution platycurtique "
                              f"plus aplatie que la normale.")
            
            # Commentaire sur les donn√©es manquantes
            if missing_pct > 5:
                comments.append(f"‚ö†Ô∏è Attention: {missing_pct:.1f}% de donn√©es manquantes n√©cessitent une vigilance "
                              f"dans l'interpr√©tation des r√©sultats.")
            
        return " ".join(comments)
    
    def interpret_categorical_stats(self, value_counts, var_name: str, missing_pct: float = 0) -> str:
        """G√©n√®re des commentaires pour les variables qualitatives"""
        comments = []
        
        n_categories = len(value_counts)
        total = value_counts.sum()
        max_freq = value_counts.iloc[0]
        max_category = value_counts.index[0]
        max_pct = (max_freq / total) * 100
        
        # Commentaire sur le nombre de modalit√©s
        if n_categories <= 3:
            comments.append(f"La variable **{var_name}** pr√©sente {n_categories} modalit√©s, "
                          f"facilitant l'analyse et l'interpr√©tation.")
        elif n_categories <= 7:
            comments.append(f"Avec {n_categories} modalit√©s, la variable **{var_name}** offre "
                          f"un niveau de d√©tail appropri√© pour l'analyse.")
        else:
            comments.append(f"La variable **{var_name}** compte {n_categories} modalit√©s, "
                          f"sugg√©rant une possible recodification pour certaines analyses.")
        
        # Commentaire sur la modalit√© dominante
        if max_pct > 50:
            comments.append(f"La modalit√© '{max_category}' domine largement avec {max_pct:.1f}% des observations, "
                          f"ce qui peut influencer les analyses crois√©es.")
        elif max_pct > 30:
            comments.append(f"La modalit√© '{max_category}' est la plus fr√©quente ({max_pct:.1f}%) "
                          f"mais ne domine pas excessivement la distribution.")
        else:
            comments.append(f"La distribution est relativement √©quilibr√©e, "
                          f"la modalit√© la plus fr√©quente ne repr√©sentant que {max_pct:.1f}% des cas.")
        
        # Analyse de l'√©quilibre des modalit√©s
        if n_categories >= 3:
            # Calcul de l'entropie pour mesurer l'√©quilibre
            proportions = value_counts / total
            entropy = -sum(p * np.log2(p) for p in proportions if p > 0)
            max_entropy = np.log2(n_categories)
            balance_ratio = entropy / max_entropy
            
            if balance_ratio > 0.8:
                comments.append("Les modalit√©s sont bien √©quilibr√©es, favorisant la robustesse des analyses statistiques.")
            elif balance_ratio > 0.6:
                comments.append("L'√©quilibre des modalit√©s est acceptable pour la plupart des analyses.")
            else:
                comments.append("Le d√©s√©quilibre entre modalit√©s n√©cessite une attention particuli√®re dans l'interpr√©tation.")
        
        # Commentaire sur les donn√©es manquantes
        if missing_pct > 5:
            comments.append(f"‚ö†Ô∏è Les {missing_pct:.1f}% de donn√©es manquantes peuvent affecter la repr√©sentativit√©.")
        
        return " ".join(comments)
    
    def interpret_correlation(self, correlation: float, var1: str, var2: str, p_value: float = None) -> str:
        """G√©n√®re des commentaires pour les corr√©lations"""
        comments = []
        
        # Interpr√©tation de la force
        abs_corr = abs(correlation)
        if abs_corr < 0.1:
            force = "tr√®s faible"
        elif abs_corr < 0.3:
            force = "faible"
        elif abs_corr < 0.5:
            force = "mod√©r√©e"
        elif abs_corr < 0.7:
            force = "forte"
        else:
            force = "tr√®s forte"
        
        direction = "positive" if correlation > 0 else "n√©gative"
        
        comments.append(f"La corr√©lation entre **{var1}** et **{var2}** est {force} et {direction} "
                       f"(r = {correlation:.3f}).")
        
        if abs_corr > 0.5:
            if correlation > 0:
                comments.append(f"Cette relation positive sugg√®re que lorsque {var1} augmente, "
                              f"{var2} tend √©galement √† augmenter.")
            else:
                comments.append(f"Cette relation n√©gative indique que lorsque {var1} augmente, "
                              f"{var2} tend √† diminuer.")
        
        # Interpr√©tation statistique
        if p_value is not None:
            if p_value < 0.001:
                comments.append("Cette corr√©lation est hautement significative (p < 0.001), "
                              "excluant pratiquement l'hypoth√®se d'absence de relation.")
            elif p_value < 0.01:
                comments.append("Cette corr√©lation est tr√®s significative (p < 0.01), "
                              "confirmant une relation statistiquement robuste.")
            elif p_value < 0.05:
                comments.append("Cette corr√©lation est significative (p < 0.05), "
                              "indiquant une relation statistiquement √©tablie.")
            else:
                comments.append("Cette corr√©lation n'est pas statistiquement significative (p ‚â• 0.05), "
                              "sugg√©rant que la relation observ√©e pourrait √™tre due au hasard.")
        
        # Commentaire sur la variance expliqu√©e
        r_squared = correlation ** 2
        if r_squared > 0.25:
            comments.append(f"Cette relation explique {r_squared*100:.1f}% de la variance," + f" repr√©sentant un pouvoir explicatif {'substantiel' if r_squared > 0.5 else 'notable'}.")
        
        return " ".join(comments)
    
    def interpret_chi2_test(self, chi2_stat: float, p_value: float, dof: int, 
                           var1: str, var2: str, cramers_v: float = None) -> str:
        """G√©n√®re des commentaires pour les tests du Chi2"""
        comments = []
        
        # Interpr√©tation du test
        if p_value < 0.001:
            comments.append(f"Le test du Chi2 r√©v√®le une association hautement significative "
                          f"entre **{var1}** et **{var2}** (œá¬≤ = {chi2_stat:.2f}, p < 0.001).")
        elif p_value < 0.01:
            comments.append(f"Le test du Chi2 indique une association tr√®s significative "
                          f"entre **{var1}** et **{var2}** (œá¬≤ = {chi2_stat:.2f}, p < 0.01).")
        elif p_value < 0.05:
            comments.append(f"Le test du Chi2 confirme une association significative "
                          f"entre **{var1}** et **{var2}** (œá¬≤ = {chi2_stat:.2f}, p < 0.05).")
        else:
            comments.append(f"Le test du Chi2 ne met pas en √©vidence d'association significative "
                          f"entre **{var1}** et **{var2}** (œá¬≤ = {chi2_stat:.2f}, p = {p_value:.3f}).")
            comments.append("Les variables semblent √™tre ind√©pendantes dans cette √©chantillon.")
        
        # Interpr√©tation du Cram√©r's V
        if cramers_v is not None and p_value < 0.05:
            if cramers_v < 0.1:
                comments.append(f"Le Cram√©r's V ({cramers_v:.3f}) indique que l'association, "
                              f"bien que significative, est de tr√®s faible intensit√©.")
            elif cramers_v < 0.3:
                comments.append(f"Le Cram√©r's V ({cramers_v:.3f}) r√©v√®le une association d'intensit√© faible.")
            elif cramers_v < 0.5:
                comments.append(f"Le Cram√©r's V ({cramers_v:.3f}) indique une association d'intensit√© mod√©r√©e.")
            else:
                comments.append(f"Le Cram√©r's V ({cramers_v:.3f}) r√©v√®le une association d'intensit√© forte.")
        
        return " ".join(comments)
    
    def interpret_group_comparison(self, test_name: str, p_value: float, 
                                 var_num: str, var_cat: str, stats_by_group: Dict) -> str:
        """G√©n√®re des commentaires pour les comparaisons de groupes"""
        comments = []
        
        # Interpr√©tation du test
        if p_value < 0.001:
            comments.append(f"Le {test_name} r√©v√®le des diff√©rences hautement significatives "
                          f"de **{var_num}** selon **{var_cat}** (p < 0.001).")
        elif p_value < 0.01:
            comments.append(f"Le {test_name} indique des diff√©rences tr√®s significatives "
                          f"de **{var_num}** selon **{var_cat}** (p < 0.01).")
        elif p_value < 0.05:
            comments.append(f"Le {test_name} confirme des diff√©rences significatives "
                          f"de **{var_num}** selon **{var_cat}** (p < 0.05).")
        else:
            comments.append(f"Le {test_name} ne met pas en √©vidence de diff√©rences significatives "
                          f"de **{var_num}** selon **{var_cat}** (p = {p_value:.3f}).")
        
        # Analyse descriptive des groupes si disponible
        if stats_by_group and p_value < 0.05:
            means = {group: stats['mean'] for group, stats in stats_by_group.items() if 'mean' in stats}
            if means:
                max_group = max(means, key=means.get)
                min_group = min(means, key=means.get)
                max_mean = means[max_group]
                min_mean = means[min_group]
                
                if len(means) == 2:
                    diff_pct = ((max_mean - min_mean) / min_mean) * 100 if min_mean != 0 else float('inf')
                    comments.append(f"Le groupe '{max_group}' pr√©sente une moyenne sup√©rieure "
                                  f"({max_mean:.2f}) √† celle du groupe '{min_group}' ({min_mean:.2f}), "
                                  f"soit une diff√©rence de {diff_pct:.1f}%.")
                else:
                    comments.append(f"Les valeurs s'√©chelonnent de {min_mean:.2f} (groupe '{min_group}') "
                                  f"√† {max_mean:.2f} (groupe '{max_group}').")
        
        return " ".join(comments)
    
    def generate_contextual_insight(self, analysis_type: str, variables: List[str]) -> str:
        """G√©n√®re des insights contextuels bas√©s sur le th√®me de l'√©tude"""
        if not self.study_theme and not self.reference_context:
            return ""
        
        insights = []
        context = f"{self.study_theme} {self.reference_context}".lower()
        
        # Insights contextuels bas√©s sur des mots-cl√©s
        if any(word in context for word in ['satisfaction', 'qualit√©', 'service']):
            if analysis_type == "categorical":
                insights.append("Ces r√©sultats peuvent r√©v√©ler des segments de client√®le "
                              "aux attentes diff√©renci√©es.")
            elif analysis_type == "correlation":
                insights.append("Cette relation m√©rite une attention particuli√®re "
                              "dans l'am√©lioration de l'exp√©rience client.")
        
        elif any(word in context for word in ['performance', 'productivit√©', 'efficacit√©']):
            if analysis_type == "group_comparison":
                insights.append("Ces √©carts de performance entre groupes sugg√®rent "
                              "des leviers d'am√©lioration sp√©cifiques.")
            elif analysis_type == "correlation":
                insights.append("Cette corr√©lation pourrait orienter les strat√©gies "
                              "d'optimisation des performances.")
        
        elif any(word in context for word in ['d√©mographique', 'population', '√¢ge', 'genre']):
            if analysis_type == "categorical":
                insights.append("Cette r√©partition refl√®te la composition d√©mographique "
                              "de l'√©chantillon √©tudi√©.")
            elif analysis_type == "association":
                insights.append("Cette association d√©mographique peut influencer "
                              "les strat√©gies de ciblage.")
        
        elif any(word in context for word in ['financier', '√©conomique', 'revenu', 'prix']):
            if analysis_type == "correlation":
                insights.append("Cette relation financi√®re m√©rite une analyse approfondie "
                              "des m√©canismes √©conomiques sous-jacents.")
            elif analysis_type == "group_comparison":
                insights.append("Ces √©carts financiers entre groupes n√©cessitent "
                              "une attention particuli√®re dans l'allocation des ressources.")
        
        return " ".join(insights)

# Configuration Plotly pour export d'images
#pio.kaleido.scope.mathjax = None
#fig.write_image("fig.png", engine="kaleido")

# Fonction pour cr√©er les dossiers de sortie
def create_output_folders():
    """Cr√©e les dossiers de sortie s'ils n'existent pas"""
    folders = [
        "Sorties/Stat_Univari√©es",
        "Sorties/Stat_Bivari√©es",
        "Sorties/Exports"
    ]
    for folder in folders:
        if not os.path.exists(folder):
            os.makedirs(folder)

# Fonction pour afficher un aper√ßu de palette
def show_palette_preview(palette_name, colors):
    """Affiche un aper√ßu de la palette de couleurs"""
    color_boxes = ""
    for color in colors[:10]:
        color_boxes += f'<div class="color-box" style="background-color: {color};"></div>'
    
    st.markdown(f"""
    <div style="display: flex; align-items: center; gap: 10px;">
        {palette_name}:</strong>
        <div class="palette-preview">{color_boxes}</div>
    </div>
    """, unsafe_allow_html=True)

# Fonction pour lister les feuilles Excel
@st.cache_data
def get_excel_sheets(uploaded_file):
    """R√©cup√®re la liste des feuilles d'un fichier Excel"""
    try:
        excel_file = pd.ExcelFile(uploaded_file)
        return excel_file.sheet_names
    except Exception as e:
        st.error(f"Erreur lors de la lecture du fichier Excel: {str(e)}")
        return []

# Fonction de chargement des donn√©es
@st.cache_data
def load_data(uploaded_file, sheet_name=None):
    """Charge les donn√©es depuis un fichier upload√©"""
    try:
        if uploaded_file.name.endswith('.csv'):
            # D√©tection automatique du s√©parateur
            sample = str(uploaded_file.read(1024), 'utf-8')
            uploaded_file.seek(0)
            
            # Essayer diff√©rents s√©parateurs
            separators = [',', ';', '\t', '|']
            best_sep = ','
            max_cols = 0
            
            for sep in separators:
                try:
                    df_test = pd.read_csv(io.StringIO(sample), sep=sep, nrows=5)
                    if df_test.shape[1] > max_cols:
                        max_cols = df_test.shape[1]
                        best_sep = sep
                except:
                    continue
            
            df = pd.read_csv(uploaded_file, sep=best_sep)
            
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            if sheet_name:
                df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
            else:
                df = pd.read_excel(uploaded_file)
        else:
            st.error("Format de fichier non support√©. Utilisez CSV ou Excel.")
            return None
            
        return df
    except Exception as e:
        st.error(f"Erreur lors du chargement: {str(e)}")
        return None

# Fonction pour l'analyse descriptive univari√©e
def analyze_numeric_variables(df, numeric_vars, ponderation=None):
    """Analyse des variables num√©riques"""
    stats_dict = {}
    
    for var in numeric_vars:
        if ponderation is None:
            series = df[var].dropna()
            stats_dict[var] = {
                'Nombre': len(series),
                'Manquantes': df[var].isnull().sum(),
                '% Manquantes': round((df[var].isnull().sum() / len(df)) * 100, 2),
                'Moyenne': round(series.mean(), 3),
                'M√©diane': round(series.median(), 3),
                '√âcart-type': round(series.std(), 3),
                'Minimum': round(series.min(), 3),
                'Q1': round(series.quantile(0.25), 3),
                'Q3': round(series.quantile(0.75), 3),
                'Maximum': round(series.max(), 3),
                'Asym√©trie': round(series.skew(), 4),
                'Aplatissement': round(series.kurtosis(), 4),
                'Total': round(series.sum(), 3)
            }
        else:
            # Analyse pond√©r√©e
            mask_valid = df[var].notna() & df[ponderation].notna()
            if mask_valid.sum() > 0:
                values = df.loc[mask_valid, var]
                weights = df.loc[mask_valid, ponderation]
                weighted_mean = np.average(values, weights=weights)
                weighted_var = np.average((values - weighted_mean)**2, weights=weights)
                
                stats_dict[var] = {
                    'Nombre': len(values),
                    'Effectif pond√©r√©': round(weights.sum(), 1),
                    'Manquantes': df[var].isnull().sum(),
                    '% Manquantes': round((df[var].isnull().sum() / len(df)) * 100, 2),
                    'Moyenne': round(weighted_mean, 3),
                    '√âcart-type': round(np.sqrt(weighted_var), 3),
                    'Minimum': round(values.min(), 3),
                    'Maximum': round(values.max(), 3),
                    'Total pond√©r√©': round(np.sum(values * weights), 3)
                }
    
    return pd.DataFrame(stats_dict).T

# Fonctions de graphiques avec streamlit-echarts ET export Plotly

def create_pie_chart_echarts(value_counts, var_name, save_folder, colors, index=0):
    """Cr√©e un graphique en secteurs avec streamlit-echarts et l'exporte en PNG
    Alternance entre disque (index pair) et anneau (index impair)"""
    
    # Alternance entre disque et anneau selon l'index
    hole_size = 0 if index % 2 == 0 else 0.4
    chart_type = "disque" if hole_size == 0 else "anneau"
    
    # Pr√©paration des donn√©es
    data = [{"value": int(val), "name": str(name)} for name, val in value_counts.items()]
    
    # Configuration ECharts
    option = {
        "tooltip": {"trigger": "item"},
        "legend": {
            "orient": "vertical",
            "left": "left",
            "textStyle": {"fontSize": 12}
        },
        "series": [
            {
                "name": var_name,
                "type": "pie",
                "radius": ["40%" if hole_size > 0 else "0%", "70%"],
                "center": ["60%", "50%"],
                "data": data,
                "emphasis": {
                    "itemStyle": {
                        "shadowBlur": 10,
                        "shadowOffsetX": 0,
                        "shadowColor": "rgba(0, 0, 0, 0.5)"
                    }
                },
                "label": {
                    "show": True,
                    "formatter": "{b}: {c} ({d}%)",
                    "fontSize": 11
                },
                "labelLine": {"show": True},
                "color": colors[:len(data)]
            }
        ],
        "title": {
            "text": f"üìä {var_name}",
            "left": "center",
            "textStyle": {"fontSize": 16, "color": "#2E4057"}
        }
    }
    
    # Affichage avec streamlit-echarts
    st_echarts(options=option, height="500px", key=f"pie_{var_name}_{index}")
    
    # Export en PNG avec Plotly
    if save_folder:
        export_pie_chart_plotly(value_counts, var_name, save_folder, colors, hole_size, chart_type)

def export_pie_chart_plotly(value_counts, var_name, save_folder, colors, hole_size, chart_type):
    """Exporte le graphique en secteurs en PNG avec Plotly"""
    fig = go.Figure(data=[go.Pie(
        labels=value_counts.index,
        values=value_counts.values,
        hole=hole_size,
        textinfo='label+percent+value',
        textfont_size=12,
        marker=dict(
            colors=colors[:len(value_counts)],
            line=dict(color='white', width=2)
        )
    )])
    
    fig.update_layout(
        title={
            'text': f"üìä {var_name}",
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 16, 'color': '#2E4057'}
        },
        font=dict(family="Arial, sans-serif", size=12),
        showlegend=True,
        legend=dict(orientation="v", yanchor="middle", y=0.5, xanchor="left", x=0.95),
        margin=dict(l=50, r=150, t=80, b=50),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        height=500,
        width=800
    )
    
    # Export
    clean_name = "".join(c for c in var_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_name = clean_name.replace(' ', '_')
    save_path = f"{save_folder}/pie_{chart_type}_{clean_name}.png"
    
    try:
        pio.write_image(fig, save_path, width=800, height=500)
    except Exception as e:
        st.warning(f"Impossible de sauvegarder le graphique: {str(e)}")

def create_bar_chart_echarts(value_counts, var_name, save_folder, colors, index=0):
    """Cr√©e un graphique en barres avec streamlit-echarts et l'exporte en PNG
    Alternance entre vertical (index pair) et horizontal (index impair)"""
    
    # Limitation √† 15 modalit√©s pour la lisibilit√©
    if len(value_counts) > 15:
        value_counts_display = value_counts.head(15)
        title_suffix = f" (Top 15 sur {len(value_counts)} modalit√©s)"
    else:
        value_counts_display = value_counts
        title_suffix = ""
    
    categories = [str(x) for x in value_counts_display.index]
    values = value_counts_display.values.tolist()
    percentages = (value_counts_display / value_counts_display.sum() * 100).round(1).tolist()
    
    # Alternance entre vertical et horizontal selon l'index
    is_horizontal = index % 2 == 1
    chart_orientation = "horizontal" if is_horizontal else "vertical"
    
    # Configuration ECharts selon l'orientation
    if is_horizontal:
        # Barres horizontales
        option = {
            "tooltip": {
                "trigger": "axis",
                "formatter": "{b}<br/>Effectif: {c}<br/>Pourcentage: {customdata}%"
            },
            "xAxis": {
                "type": "value",
                "axisLabel": {"fontSize": 11}
            },
            "yAxis": {
                "type": "category",
                "data": categories,
                "axisLabel": {"fontSize": 11}
            },
            "series": [
                {
                    "data": [{"value": val, "customdata": pct} for val, pct in zip(values, percentages)],
                    "type": "bar",
                    "itemStyle": {"color": colors[0]},
                    "label": {
                        "show": True,
                        "position": "right",
                        "fontSize": 11
                    }
                }
            ],
            "title": {
                "text": f"üìä {var_name}{title_suffix}",
                "left": "center",
                "textStyle": {"fontSize": 16, "color": "#2E4057"}
            },
            "grid": {
                "left": "20%",
                "right": "10%",
                "bottom": "10%",
                "top": "15%"
            }
        }
    else:
        # Barres verticales
        option = {
            "tooltip": {
                "trigger": "axis",
                "formatter": "{b}<br/>Effectif: {c}<br/>Pourcentage: {customdata}%"
            },
            "xAxis": {
                "type": "category",
                "data": categories,
                "axisLabel": {
                    "rotate": 45 if len(categories) > 8 else 0,
                    "fontSize": 11
                }
            },
            "yAxis": {
                "type": "value",
                "axisLabel": {"fontSize": 11}
            },
            "series": [
                {
                    "data": [{"value": val, "customdata": pct} for val, pct in zip(values, percentages)],
                    "type": "bar",
                    "itemStyle": {"color": colors[0]},
                    "label": {
                        "show": True,
                        "position": "top",
                        "fontSize": 11
                    }
                }
            ],
            "title": {
                "text": f"üìä {var_name}{title_suffix}",
                "left": "center",
                "textStyle": {"fontSize": 16, "color": "#2E4057"}
            },
            "grid": {
                "left": "10%",
                "right": "10%",
                "bottom": "20%",
                "top": "15%"
            }
        }
    
    # Affichage avec streamlit-echarts
    st_echarts(options=option, height="500px", key=f"bar_{var_name}_{index}")
    
    # Export en PNG avec Plotly
    if save_folder:
        export_bar_chart_plotly(value_counts_display, var_name, save_folder, colors, 
                               title_suffix, chart_orientation)

def export_bar_chart_plotly(value_counts, var_name, save_folder, colors, title_suffix, orientation):
    """Exporte le graphique en barres en PNG avec Plotly"""
    
    if orientation == "horizontal":
        # Barres horizontales
        fig = go.Figure(data=[go.Bar(
            y=value_counts.index,
            x=value_counts.values,
            text=value_counts.values,
            textposition='outside',
            textfont=dict(size=12, color='#2E4057'),
            marker=dict(color=colors[0], line=dict(color='white', width=1)),
            orientation='h',
            hovertemplate='<b>%{y}</b><br>Effectif: %{x}<br>Pourcentage: %{customdata:.1f}%<br><extra></extra>',
            customdata=(value_counts / value_counts.sum() * 100)
        )])
        
        fig.update_layout(
            title=dict(text=f"üìä {var_name}{title_suffix}", x=0.5, xanchor='center', font=dict(size=16, color='#2E4057')),
            #yaxis=dict(title=var_name, tickfont=dict(size=12)),
            xaxis=dict(title="Effectif", tickfont=dict(size=14), gridcolor='rgba(128,128,128,0.2)'),
            font=dict(family="Arial, sans-serif"),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            margin=dict(l=150, r=50, t=80, b=80),
            height=500,
            width=800
        )
    else:
        # Barres verticales
        fig = go.Figure(data=[go.Bar(
            x=value_counts.index,
            y=value_counts.values,
            text=value_counts.values,
            textposition='outside',
            textfont=dict(size=12, color='#2E4057'),
            marker=dict(color=colors[0], line=dict(color='white', width=1)),
            hovertemplate='<b>%{x}</b><br>Effectif: %{y}<br>Pourcentage: %{customdata:.1f}%<br><extra></extra>',
            customdata=(value_counts / value_counts.sum() * 100)
        )])
        
        fig.update_layout(
            title=dict(text=f"üìä {var_name}{title_suffix}", x=0.5, xanchor='center', font=dict(size=16, color='#2E4057')),
            #xaxis=dict(title=var_name, tickfont=dict(size=12), tickangle=45 if len(value_counts) > 8 else 0),
            yaxis=dict(title="Effectif", tickfont=dict(size=14), gridcolor='rgba(128,128,128,0.2)'),
            font=dict(family="Arial, sans-serif"),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            margin=dict(l=80, r=50, t=80, b=100),
            height=500,
            width=800
        )
    
    clean_name = "".join(c for c in var_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_name = clean_name.replace(' ', '_')
    save_path = f"{save_folder}/bar_{orientation}_{clean_name}.png"
    
    try:
        pio.write_image(fig, save_path, width=800, height=500)
    except Exception as e:
        st.warning(f"Impossible de sauvegarder le graphique: {str(e)}")

def create_boxplot_echarts(df, var_cible, var_num, save_folder, colors):
    """Cr√©e un boxplot avec streamlit-echarts et l'exporte en PNG"""
    
    groups = df.groupby(var_cible)[var_num].apply(list).to_dict()
    
    # Calculer les statistiques pour chaque groupe
    boxplot_data = []
    categories = []
    
    for group_name, group_values in groups.items():
        if len(group_values) > 0:
            q1 = np.percentile(group_values, 25)
            median = np.percentile(group_values, 50)
            q3 = np.percentile(group_values, 75)
            min_val = np.min(group_values)
            max_val = np.max(group_values)
            
            boxplot_data.append([min_val, q1, median, q3, max_val])
            categories.append(str(group_name))
    
    # Configuration ECharts
    option = {
        "title": {
            "text": f"üìä Distribution de {var_num} selon {var_cible}",
            "left": "center",
            "textStyle": {"fontSize": 16, "color": "#2E4057"}
        },
        "tooltip": {"trigger": "item"},
        "xAxis": {
            "type": "category",
            "data": categories,
            "axisLabel": {"fontSize": 11}
        },
        "yAxis": {
            "type": "value",
            "name": var_num,
            "axisLabel": {"fontSize": 11}
        },
        "series": [
            {
                "name": var_num,
                "type": "boxplot",
                "data": boxplot_data,
                "itemStyle": {"color": colors[0]}
            }
        ],
        "grid": {
            "left": "10%",
            "right": "10%",
            "bottom": "15%",
            "top": "15%"
        }
    }
    
    # Affichage avec streamlit-echarts
    st_echarts(options=option, height="500px", key=f"boxplot_{var_cible}_{var_num}")
    
    # Export en PNG avec Plotly
    if save_folder:
        export_boxplot_plotly(df, var_cible, var_num, save_folder, colors)

def export_boxplot_plotly(df, var_cible, var_num, save_folder, colors):
    """Exporte le boxplot en PNG avec Plotly"""
    fig = px.box(df, x=var_cible, y=var_num, color=var_cible, color_discrete_sequence=colors,
                 title=f"üìä Distribution de {var_num} selon {var_cible}")
    
    fig.update_layout(
        title={'x': 0.5, 'xanchor': 'center', 'font': {'size': 16, 'color': '#2E4057'}},
        xaxis_title=var_cible, yaxis_title=var_num, showlegend=False, height=500,
        font=dict(family="Arial, sans-serif"), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
    )
    
    clean_cible = "".join(c for c in var_cible if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_num = "".join(c for c in var_num if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_cible = clean_cible.replace(' ', '_')
    clean_num = clean_num.replace(' ', '_')
    save_path = f"{save_folder}/boxplot_{clean_num}_par_{clean_cible}.png"
    
    try:
        pio.write_image(fig, save_path, width=800, height=500)
    except Exception as e:
        st.warning(f"Impossible de sauvegarder le graphique: {str(e)}")

def create_stacked_bar_echarts(df, var_cible, var_cat, save_folder, colors):
    """Cr√©e un graphique en barres empil√©es avec streamlit-echarts et l'exporte en PNG"""
    
    # Calcul des pourcentages
    crosstab_pct = pd.crosstab(df[var_cat], df[var_cible], normalize='index') * 100
    
    categories = [str(x) for x in crosstab_pct.index]
    series_data = []
    
    for i, col in enumerate(crosstab_pct.columns):
        series_data.append({
            "name": str(col),
            "type": "bar",
            "stack": "total",
            "data": crosstab_pct[col].round(2).tolist(),
            "itemStyle": {"color": colors[i % len(colors)]},
            "label": {
                "show": True,
                "position": "inside",
                "formatter": "{c}%",
                "fontSize": 10
            }
        })
    
    # Configuration ECharts
    option = {
        "title": {
            "text": f"üìä R√©partition de {var_cat} selon {var_cible} (%)",
            "left": "center",
            "textStyle": {"fontSize": 16, "color": "#2E4057"}
        },
        "tooltip": {
            "trigger": "axis",
            "formatter": "{b}<br/>{a}: {c}%"
        },
        "legend": {
            "data": [str(x) for x in crosstab_pct.columns],
            "top": "bottom",
            "textStyle": {"fontSize": 12}
        },
        "xAxis": {
            "type": "category",
            "data": categories,
            "axisLabel": {"fontSize": 11}
        },
        "yAxis": {
            "type": "value",
            "name": "Pourcentage (%)",
            "axisLabel": {"fontSize": 11}
        },
        "series": series_data,
        "grid": {
            "left": "10%",
            "right": "10%",
            "bottom": "20%",
            "top": "15%"
        }
    }
    
    # Affichage avec streamlit-echarts
    st_echarts(options=option, height="500px", key=f"stacked_{var_cat}_{var_cible}")
    
    # Export en PNG avec Plotly
    if save_folder:
        export_stacked_bar_plotly(df, var_cible, var_cat, save_folder, colors)

def export_stacked_bar_plotly(df, var_cible, var_cat, save_folder, colors):
    """Exporte le graphique en barres empil√©es en PNG avec Plotly"""
    crosstab_pct = pd.crosstab(df[var_cat], df[var_cible], normalize='index') * 100
    
    fig = go.Figure()
    
    for i, col in enumerate(crosstab_pct.columns):
        fig.add_trace(go.Bar(
            name=str(col), x=crosstab_pct.index, y=crosstab_pct[col],
            marker_color=colors[i % len(colors)],
            text=crosstab_pct[col].round(1).values, texttemplate='%{text}%', textposition='inside'
        ))
    
    fig.update_layout(
        title={'text': f"üìä R√©partition de {var_cat} selon {var_cible} (%)", 'x': 0.5, 'xanchor': 'center',
               'font': {'size': 16, 'color': '#2E4057'}},
        xaxis_title=var_cat, yaxis_title="Pourcentage (%)", barmode='stack', height=500,
        font=dict(family="Arial, sans-serif", size=12), legend=dict(title=var_cible),
        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', margin=dict(l=80, r=50, t=80, b=80)
    )
    
    clean_cible = "".join(c for c in var_cible if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_cat = "".join(c for c in var_cat if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_cible = clean_cible.replace(' ', '_')
    clean_cat = clean_cat.replace(' ', '_')
    save_path = f"{save_folder}/stacked_{clean_cat}_selon_{clean_cible}.png"
    
    try:
        pio.write_image(fig, save_path, width=800, height=500)
    except Exception as e:
        st.warning(f"Impossible de sauvegarder le graphique: {str(e)}")

def create_heatmap_echarts(df, var_cible, var_cat, save_folder, colors):
    """Cr√©e une heatmap avec streamlit-echarts et l'exporte en PNG"""
    
    crosstab_pct = pd.crosstab(df[var_cible], df[var_cat], normalize='index') * 100
    
    # Pr√©parer les donn√©es pour la heatmap
    data = []
    for i, row_name in enumerate(crosstab_pct.index):
        for j, col_name in enumerate(crosstab_pct.columns):
            data.append([j, i, round(crosstab_pct.loc[row_name, col_name], 1)])
    
    # Configuration ECharts
    option = {
        "title": {
            "text": f"üî• Heatmap: {var_cible} vs {var_cat} (%)",
            "left": "center",
            "textStyle": {"fontSize": 16, "color": "#2E4057"}
        },
        "tooltip": {
            "position": "top",
            "formatter": "{b}<br/>{a}: {c}%"
        },
        "grid": {"height": "60%", "top": "10%"},
        "xAxis": {
            "type": "category",
            "data": [str(x) for x in crosstab_pct.columns],
            "splitArea": {"show": True},
            "axisLabel": {"fontSize": 11}
        },
        "yAxis": {
            "type": "category",
            "data": [str(x) for x in crosstab_pct.index],
            "splitArea": {"show": True},
            "axisLabel": {"fontSize": 11}
        },
        "visualMap": {
            "min": 0,
            "max": crosstab_pct.values.max(),
            "calculable": True,
            "orient": "horizontal",
            "left": "center",
            "bottom": "15%",
            "inRange": {"color": ["#f7f7f7", colors[0]]}
        },
        "series": [
            {
                "name": "Pourcentage",
                "type": "heatmap",
                "data": data,
                "label": {"show": True, "fontSize": 11}
            }
        ]
    }
    
    # Affichage avec streamlit-echarts
    st_echarts(options=option, height="500px", key=f"heatmap_{var_cible}_{var_cat}")
    
    # Export en PNG avec Plotly
    if save_folder:
        export_heatmap_plotly(df, var_cible, var_cat, save_folder)

def export_heatmap_plotly(df, var_cible, var_cat, save_folder):
    """Exporte la heatmap en PNG avec Plotly"""
    crosstab_pct = pd.crosstab(df[var_cible], df[var_cat], normalize='index') * 100
    
    fig = go.Figure(data=go.Heatmap(
        z=crosstab_pct.values, x=crosstab_pct.columns, y=crosstab_pct.index,
        colorscale='Blues', text=crosstab_pct.round(1).values, texttemplate='%{text}%',
        textfont={"size": 12}, hoverongaps=False, colorbar=dict(title="Pourcentage (%)")
    ))
    
    fig.update_layout(
        title={'text': f"üî• Heatmap: {var_cible} vs {var_cat} (%)", 'x': 0.5, 'xanchor': 'center',
               'font': {'size': 16, 'color': '#2E4057'}},
        xaxis_title=var_cat, yaxis_title=var_cible, height=500, font=dict(family="Arial, sans-serif"),
        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
    )
    
    clean_cible = "".join(c for c in var_cible if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_cat = "".join(c for c in var_cat if c.isalnum() or c in (' ', '-', '_')).rstrip()
    clean_cible = clean_cible.replace(' ', '_')
    clean_cat = clean_cat.replace(' ', '_')
    save_path = f"{save_folder}/heatmap_{clean_cible}_vs_{clean_cat}.png"
    
    try:
        pio.write_image(fig, save_path, width=800, height=500)
    except Exception as e:
        st.warning(f"Impossible de sauvegarder le graphique: {str(e)}")

# Fonctions pour la g√©n√©ration de documents Word
def create_word_document_header(doc, title, subtitle=None):
    """Cr√©e l'en-t√™te du document Word avec mise en forme"""
    # Titre principal
    title_para = doc.add_heading(title, 0)
    title_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    if subtitle:
        subtitle_para = doc.add_paragraph(subtitle)
        subtitle_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        subtitle_run = subtitle_para.runs[0]
        subtitle_run.font.size = Pt(14)
        subtitle_run.font.italic = True
    
    # Ligne de s√©paration
    doc.add_paragraph("=" * 60).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph()


def add_dataframe_to_doc(doc, df, title=None):
    """Ajoute un DataFrame au document Word sous forme de tableau avec index"""
    if title:
        doc.add_heading(title, level=3)
    
    # Cr√©er le tableau avec une colonne de plus pour les index
    table = doc.add_table(rows=1, cols=len(df.columns) + 1)
    table.style = 'Light Grid Accent 1'
    table.alignment = WD_TABLE_ALIGNMENT.CENTER
    
    # En-t√™tes
    header_cells = table.rows[0].cells
    header_cells[0].text = "Index"  # Colonne des index
    header_cells[0].paragraphs[0].runs[0].font.bold = True
    for i, column in enumerate(df.columns):
        header_cells[i + 1].text = str(column)
        header_cells[i + 1].paragraphs[0].runs[0].font.bold = True
    
    # Donn√©es
    for idx, row in df.iterrows():
        row_cells = table.add_row().cells
        row_cells[0].text = str(idx)  # Ajouter l'index
        for i, value in enumerate(row):
            row_cells[i + 1].text = str(value)
    
    doc.add_paragraph()


def add_image_to_doc(doc, image_path, title=None, width=Inches(6)):
    """Ajoute une image au document Word"""
    if title:
        doc.add_heading(title, level=3)
    
    try:
        if os.path.exists(image_path):
            paragraph = doc.add_paragraph()
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()
            run.add_picture(image_path, width=width)
            doc.add_paragraph()
        else:
            doc.add_paragraph(f"‚ö†Ô∏è Image non trouv√©e: {image_path}")
    except Exception as e:
        doc.add_paragraph(f"‚ö†Ô∏è Erreur lors de l'insertion de l'image: {str(e)}")

def create_word_report(df, numeric_vars, categorical_vars, resultats_bivariees=None, 
                      var_cible=None, ponderation=None, palette_name=None, selected_sheet=None):
    """Cr√©e un rapport Word complet avec toutes les analyses"""
    doc = Document()
    
    # En-t√™te du document
    create_word_document_header(
        doc, 
        "üìä RAPPORT D'ANALYSE STATISTIQUE",
        f"G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}"
    )
    
    # Informations g√©n√©rales
    doc.add_heading("üìã Informations g√©n√©rales", level=1)
    
    info_data = [
        ["Nombre de lignes", str(df.shape[0])],
        ["Nombre de colonnes", str(df.shape[1])],
        ["Variables num√©riques", str(len(numeric_vars))],
        ["Variables qualitatives", str(len(categorical_vars))],
        ["Feuille Excel", selected_sheet if selected_sheet else "N/A (fichier CSV)"],
        ["Pond√©ration utilis√©e", ponderation if ponderation else "Aucune"],
        ["Palette de couleurs", palette_name if palette_name else "D√©faut"],
        ["Date d'analyse", datetime.now().strftime('%d/%m/%Y √† %H:%M')]
    ]
    
    info_table = doc.add_table(rows=1, cols=2)
    info_table.style = 'Light List Accent 1'
    info_table.alignment = WD_TABLE_ALIGNMENT.CENTER
    
    # En-t√™tes du tableau d'informations
    header_cells = info_table.rows[0].cells
    header_cells[0].text = "Param√®tre"
    header_cells[1].text = "Valeur"
    for cell in header_cells:
        cell.paragraphs[0].runs[0].font.bold = True
    
    # Donn√©es du tableau d'informations
    for param, valeur in info_data:
        row_cells = info_table.add_row().cells
        row_cells[0].text = param
        row_cells[1].text = valeur
    
    doc.add_page_break()
    
    # Analyses univari√©es
    doc.add_heading("üìä ANALYSES UNIVARI√âES", level=1)
    
    # Variables num√©riques
    if numeric_vars:
        doc.add_heading("üî¢ Variables num√©riques", level=2)
        
        # Calculer les statistiques
        stats_table = analyze_numeric_variables(df, numeric_vars, ponderation)
        add_dataframe_to_doc(doc, stats_table, "Statistiques descriptives")
        
        doc.add_paragraph("Les statistiques ci-dessus pr√©sentent les mesures de tendance centrale, "
                         "de dispersion et de forme pour chaque variable num√©rique.")
        if ponderation:
            doc.add_paragraph(f"‚öñÔ∏è Analyses pond√©r√©es avec la variable: {ponderation}")
    
    # Variables qualitatives
    if categorical_vars:
        doc.add_heading("üìù Variables qualitatives", level=2)
        
        for i, var in enumerate(categorical_vars):
            doc.add_heading(f"Variable: {var}", level=3)
            
            # Calculer les fr√©quences
            if ponderation is None:
                value_counts = df[var].value_counts()
                total = value_counts.sum()
            else:
                mask_valid = df[var].notna() & df[ponderation].notna()
                if mask_valid.sum() > 0:
                    value_counts = df[mask_valid].groupby(var)[ponderation].sum().sort_values(ascending=False)
                    total = value_counts.sum()
                else:
                    continue
            
            # Tableau de fr√©quences
            freq_table = pd.DataFrame({
                'Modalit√©': value_counts.index,
                'Effectif': value_counts.values,
                'Fr√©quence (%)': (value_counts / total * 100).round(2).values
            })
            
            add_dataframe_to_doc(doc, freq_table, f"R√©partition de {var}")
            
            # Informations sur la variable
            n_categories = len(value_counts)
            missing_count = df[var].isnull().sum()
            
            info_text = f"‚Ä¢ Nombre de modalit√©s: {n_categories}\n"
            info_text += f"‚Ä¢ Valeurs manquantes: {missing_count} ({(missing_count/len(df)*100):.1f}%)\n"
            if ponderation:
                info_text += f"‚Ä¢ Effectif pond√©r√© total: {total:.0f}\n"
            
            doc.add_paragraph(info_text)
            
            # Ajouter le graphique si disponible
            clean_name = "".join(c for c in var if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_name = clean_name.replace(' ', '_')
            
            if n_categories <= 3:
                # Graphique en secteurs (alternance disque/anneau)
                chart_type = "disque" if i % 2 == 0 else "anneau"
                image_path = f"Sorties/Stat_Univari√©es/pie_{chart_type}_{clean_name}.png"
                add_image_to_doc(doc, image_path, f"Graphique: {var}")
            else:
                # Graphique en barres (alternance vertical/horizontal)
                chart_orientation = "vertical" if i % 2 == 0 else "horizontal"
                image_path = f"Sorties/Stat_Univari√©es/bar_{chart_orientation}_{clean_name}.png"
                add_image_to_doc(doc, image_path, f"Graphique: {var}")
    
    # Analyses bivari√©es
    if resultats_bivariees and var_cible:
        doc.add_page_break()
        doc.add_heading("üîó ANALYSES BIVARI√âES", level=1)
        
        doc.add_paragraph(f"Variable cible: {var_cible}")
        doc.add_paragraph(f"Nombre d'analyses: {len(resultats_bivariees)}")
        doc.add_paragraph()
        
        for var_name, resultats in resultats_bivariees.items():
            doc.add_heading(f"Analyse: {var_cible} √ó {var_name}", level=2)
            
            # Type d'analyse et informations
            doc.add_paragraph(f"Type d'analyse: {resultats['type_analyse']}")
            doc.add_paragraph(f"Nombre d'observations: {resultats['n_observations']}")
            
            # Tableau principal
            if 'tableau_principal' in resultats and resultats['tableau_principal'] is not None:
                add_dataframe_to_doc(doc, resultats['tableau_principal'], "Tableau principal")
            
            # Tableau secondaire
            if 'tableau_secondaire' in resultats and resultats['tableau_secondaire'] is not None:
                add_dataframe_to_doc(doc, resultats['tableau_secondaire'], "Tableau des pourcentages")
            
            """# Tests statistiques
            if 'tests' in resultats and resultats['tests']:
                doc.add_heading("Tests statistiques", level=3)
                tests_df = pd.DataFrame(resultats['tests'])
                add_dataframe_to_doc(doc, tests_df)
                
                # R√©sum√© du test principal
                if resultats.get('test_principal'):
                    doc.add_paragraph(f"Test principal: {resultats['test_principal']}")
                    if resultats.get('p_value_principal'):
                        doc.add_paragraph(f"P-value: {resultats['p_value_principal']}")
                        if resultats.get('significatif_principal'):
                            doc.add_paragraph("‚úÖ R√©sultat significatif (p < 0.05)")
                        else:
                            doc.add_paragraph("‚ùå R√©sultat non significatif (p ‚â• 0.05)")"""
            
            # Ajouter les graphiques
            clean_cible = "".join(c for c in var_cible if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_var = "".join(c for c in var_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_cible = clean_cible.replace(' ', '_')
            clean_var = clean_var.replace(' ', '_')
            
            if resultats['type_analyse'] == 'Num√©rique vs Cat√©gorielle':
                # Boxplot
                image_path = f"Sorties/Stat_Bivari√©es/boxplot_{clean_var}_par_{clean_cible}.png"
                add_image_to_doc(doc, image_path, "Distribution par groupe (Boxplot)", width=Inches(5))
                
            elif resultats['type_analyse'] == 'Cat√©gorielle vs Cat√©gorielle':
                # Barres empil√©es
                image_path = f"Sorties/Stat_Bivari√©es/stacked_{clean_var}_selon_{clean_cible}.png"
                add_image_to_doc(doc, image_path, "R√©partition (Barres empil√©es)", width=Inches(5))
                
                # Heatmap
                image_path = f"Sorties/Stat_Bivari√©es/heatmap_{clean_cible}_vs_{clean_var}.png"
                add_image_to_doc(doc, image_path, "Carte de chaleur (Heatmap)", width=Inches(5))
                
            elif resultats['type_analyse'] == 'Num√©rique vs Num√©rique':
                # Nuage de points
                image_path = f"Sorties/Stat_Bivari√©es/scatter_{clean_cible}_vs_{clean_var}.png"
                add_image_to_doc(doc, image_path, "Nuage de points", width=Inches(5))
            
            doc.add_paragraph()
    
    # Conclusion
    doc.add_page_break()
    doc.add_heading("üìã CONCLUSION", level=1)
    
    conclusion_text = "Ce rapport pr√©sente une analyse statistique compl√®te des donn√©es fournies. "
    conclusion_text += f"L'analyse porte sur {df.shape[0]} observations et {df.shape[1]} variables, "
    conclusion_text += f"dont {len(numeric_vars)} variables num√©riques et {len(categorical_vars)} variables qualitatives.\n\n"
    
    if ponderation:
        conclusion_text += f"Les analyses ont √©t√© pond√©r√©es en utilisant la variable '{ponderation}'.\n\n"
    
    if resultats_bivariees:
        conclusion_text += f"Les analyses bivari√©es ont permis d'√©tudier les relations entre la variable cible '{var_cible}' "
        conclusion_text += f"et {len(resultats_bivariees)} autres variables.\n\n"
    
    conclusion_text += "Les graphiques et tableaux pr√©sent√©s dans ce rapport permettent une compr√©hension "
    conclusion_text += "approfondie de la structure et des relations pr√©sentes dans les donn√©es."
    
    doc.add_paragraph(conclusion_text)
    
    # Note technique
    doc.add_heading("üìå Note technique", level=2)
    tech_note = "Ce rapport a √©t√© g√©n√©r√© automatiquement par l'Analyseur Statistique Pro. "
    tech_note += "Les analyses statistiques ont √©t√© r√©alis√©es avec Python et les biblioth√®ques "
    tech_note += "pandas, scipy et numpy. Les graphiques ont √©t√© cr√©√©s avec plotly et streamlit-echarts."
    
    doc.add_paragraph(tech_note)
    
    return doc

# Nouvelle fonction Word avec commentaires automatiques
def create_word_report_with_comments(df, numeric_vars, categorical_vars, resultats_bivariees=None, 
                                   var_cible=None, ponderation=None, palette_name=None, 
                                   selected_sheet=None, commentator=None):
    """Version am√©lior√©e avec commentaires automatiques"""
    doc = Document()
    
    # Utiliser le commentator s'il est fourni
    if commentator is None:
        commentator = StatisticalCommentator()
    
    # En-t√™te du document
    create_word_document_header(
        doc, 
        "üìä RAPPORT D'ANALYSE STATISTIQUE COMMENT√â",
        f"G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}"
    )
    
    # Ajout du contexte de l'√©tude si fourni
    if commentator.study_theme or commentator.reference_context:
        doc.add_heading("üéØ Contexte de l'√©tude", level=1)
        if commentator.study_theme:
            doc.add_paragraph(f"Th√®me: {commentator.study_theme}")
        if commentator.reference_context:
            doc.add_paragraph("Contexte de r√©f√©rence:")
            doc.add_paragraph(commentator.reference_context[:500] + "..." if len(commentator.reference_context) > 500 else commentator.reference_context)
        doc.add_page_break()
    
    # Informations g√©n√©rales (m√™me code que l'original)
    doc.add_heading("üìã Informations g√©n√©rales", level=1)
    
    info_data = [
        ["Nombre de lignes", str(df.shape[0])],
        ["Nombre de colonnes", str(df.shape[1])],
        ["Variables num√©riques", str(len(numeric_vars))],
        ["Variables qualitatives", str(len(categorical_vars))],
        ["Feuille Excel", selected_sheet if selected_sheet else "N/A (fichier CSV)"],
        ["Pond√©ration utilis√©e", ponderation if ponderation else "Aucune"],
        ["Palette de couleurs", palette_name if palette_name else "D√©faut"],
        ["Date d'analyse", datetime.now().strftime('%d/%m/%Y √† %H:%M')]
    ]
    
    info_table = doc.add_table(rows=1, cols=2)
    info_table.style = 'Light List Accent 1'
    info_table.alignment = WD_TABLE_ALIGNMENT.CENTER
    
    header_cells = info_table.rows[0].cells
    header_cells[0].text = "Param√®tre"
    header_cells[1].text = "Valeur"
    for cell in header_cells:
        cell.paragraphs[0].runs[0].font.bold = True
    
    for param, valeur in info_data:
        row_cells = info_table.add_row().cells
        row_cells[0].text = param
        row_cells[1].text = valeur
    
    doc.add_page_break()
    
    # Analyses univari√©es avec commentaires
    doc.add_heading(" ANALYSES UNIVARI√âES COMMENT√âES", level=1)
    
    # Variables num√©riques avec commentaires
    if numeric_vars:
        doc.add_heading("üî¢ Variables num√©riques", level=2)
        
        stats_table = analyze_numeric_variables(df, numeric_vars, ponderation)
        add_dataframe_to_doc(doc, stats_table, "Statistiques descriptives")
        
        # Commentaires par variable num√©rique
        doc.add_heading("Interpr√©tations des variables num√©riques", level=3)
        for var in numeric_vars:
            if var in stats_table.index:
                stats_dict = stats_table.loc[var].to_dict()
                comment = commentator.interpret_descriptive_stats(stats_dict, var, "numeric")
                contextual_insight = commentator.generate_contextual_insight("numeric", [var])
                
                doc.add_paragraph(f"**{var}:**", style='Heading 4')
                doc.add_paragraph(comment)
                #if contextual_insight:
                    #doc.add_paragraph(f"üí° Insight contextuel: {contextual_insight}")
                doc.add_paragraph()
    
    # Variables qualitatives avec commentaires
    if categorical_vars:
        doc.add_heading("üìù Variables qualitatives", level=2)
        
        for i, var in enumerate(categorical_vars):
            doc.add_heading(f"Variable: {var}", level=3)
            
            # Calcul des fr√©quences
            if ponderation is None:
                value_counts = df[var].value_counts()
                total = value_counts.sum()
            else:
                mask_valid = df[var].notna() & df[ponderation].notna()
                if mask_valid.sum() > 0:
                    value_counts = df[mask_valid].groupby(var)[ponderation].sum().sort_values(ascending=False)
                    total = value_counts.sum()
                else:
                    continue
            
            # Tableau de fr√©quences
            freq_table = pd.DataFrame({
                'Modalit√©': value_counts.index,
                'Effectif': value_counts.values,
                'Fr√©quence (%)': (value_counts / total * 100).round(2).values
            })
            
            add_dataframe_to_doc(doc, freq_table, f"R√©partition de {var}")
            
            # Commentaires automatiques
            missing_pct = (df[var].isnull().sum() / len(df)) * 100
            comment = commentator.interpret_categorical_stats(value_counts, var, missing_pct)
            contextual_insight = commentator.generate_contextual_insight("categorical", [var])
            
            doc.add_heading(" Interpr√©tation", level=4)
            doc.add_paragraph(comment)
            #if contextual_insight:
                #doc.add_paragraph(f"üí° Insight contextuel: {contextual_insight}")
            
            # Ajouter le graphique
            clean_name = "".join(c for c in var if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_name = clean_name.replace(' ', '_')
            
            n_categories = len(value_counts)
            if n_categories <= 3:
                chart_type = "disque" if i % 2 == 0 else "anneau"
                image_path = f"Sorties/Stat_Univari√©es/pie_{chart_type}_{clean_name}.png"
                add_image_to_doc(doc, image_path, f"Graphique: {var}")
            else:
                chart_orientation = "vertical" if i % 2 == 0 else "horizontal"
                image_path = f"Sorties/Stat_Univari√©es/bar_{chart_orientation}_{clean_name}.png"
                add_image_to_doc(doc, image_path, f"Graphique: {var}")
    
    # Analyses bivari√©es avec commentaires d√©taill√©s
    if resultats_bivariees and var_cible:
        doc.add_page_break()
        doc.add_heading("ANALYSES BIVARI√âES COMMENT√âES", level=1)
        
        doc.add_paragraph(f"Variable cible: {var_cible}")
        doc.add_paragraph(f"Nombre d'analyses: {len(resultats_bivariees)}")
        
        # Synth√®se des r√©sultats significatifs
        resultats_significatifs = []
        for var_name, resultats in resultats_bivariees.items():
            if resultats.get('significatif_principal', False):
                resultats_significatifs.append((var_name, resultats))
        
        if resultats_significatifs:
            doc.add_heading("üéØ Synth√®se des relations significatives", level=2)
            doc.add_paragraph(f"Sur {len(resultats_bivariees)} analyses effectu√©es, "
                            f"{len(resultats_significatifs)} r√©v√®lent des relations statistiquement significatives:")
            
            for var_name, resultats in resultats_significatifs:
                doc.add_paragraph(f"‚Ä¢ **{var_cible} √ó {var_name}** ({resultats['type_analyse']}) - "
                                f"p = {resultats.get('p_value_principal', 'N/A')}")
        
        # Analyses d√©taill√©es avec commentaires
        doc.add_heading("üìä Analyses d√©taill√©es", level=2)
        
        for var_name, resultats in resultats_bivariees.items():
            doc.add_heading(f"Analyse: {var_cible} √ó {var_name}", level=3)
            
            # Informations de base
            doc.add_paragraph(f"Type d'analyse: {resultats['type_analyse']}")
            doc.add_paragraph(f"Nombre d'observations: {resultats['n_observations']}")
            
            # Tableaux
            if 'tableau_principal' in resultats and resultats['tableau_principal'] is not None:
                add_dataframe_to_doc(doc, resultats['tableau_principal'], "Tableau principal")
            
            if 'tableau_secondaire' in resultats and resultats['tableau_secondaire'] is not None:
                add_dataframe_to_doc(doc, resultats['tableau_secondaire'], "Tableau des pourcentages")
            """
            # Tests statistiques
            if 'tests' in resultats and resultats['tests']:
                doc.add_heading("Tests statistiques", level=4)
                tests_df = pd.DataFrame(resultats['tests'])
                add_dataframe_to_doc(doc, tests_df)
            
            # Commentaires automatiques d√©taill√©s"""
            doc.add_heading("üí¨ Interpr√©tation automatique", level=4)
            
            comment = ""
            contextual_insight = ""
            
            if resultats['type_analyse'] == 'Num√©rique vs Num√©rique':
                # Commentaire sur la corr√©lation
                for test in resultats.get('tests', []):
                    if test.get('Test') == 'Corr√©lation de Pearson':
                        correlation = test.get('Coefficient', 0)
                        p_value = test.get('p-value', None)
                        comment = commentator.interpret_correlation(correlation, var_cible, var_name, p_value)
                        contextual_insight = commentator.generate_contextual_insight("correlation", [var_cible, var_name])
                        break
            
            elif resultats['type_analyse'] == 'Cat√©gorielle vs Cat√©gorielle':
                # Commentaire sur l'association
                chi2_stat = None
                p_value = None
                cramers_v = None
                
                for test in resultats.get('tests', []):
                    if test.get('Test') == 'Test du Chi2':
                        chi2_stat = test.get('Statistique')
                        p_value = test.get('p-value')
                    elif test.get('Test') == "Cram√©r's V":
                        cramers_v = test.get('Statistique')
                
                if chi2_stat is not None and p_value is not None:
                    comment = commentator.interpret_chi2_test(chi2_stat, p_value, 
                                                            resultats.get('dof', 1), 
                                                            var_cible, var_name, cramers_v)
                    contextual_insight = commentator.generate_contextual_insight("association", [var_cible, var_name])
            
            elif resultats['type_analyse'] == 'Num√©rique vs Cat√©gorielle':
                # Commentaire sur la comparaison de groupes
                test_principal = resultats.get('test_principal', '')
                p_value = resultats.get('p_value_principal', None)
                
                if p_value is not None:
                    stats_by_group = {}
                    if 'tableau_principal' in resultats:
                        try:
                            tableau = resultats['tableau_principal']
                            for group in tableau.index:
                                stats_by_group[group] = {
                                    'mean': tableau.loc[group, 'mean'] if 'mean' in tableau.columns else None,
                                    'count': tableau.loc[group, 'count'] if 'count' in tableau.columns else None
                                }
                        except:
                            pass
                    
                    comment = commentator.interpret_group_comparison(test_principal, p_value, 
                                                                   var_name, var_cible, stats_by_group)
                    contextual_insight = commentator.generate_contextual_insight("group_comparison", [var_cible, var_name])
            
            if comment:
                doc.add_paragraph(comment)
            #if contextual_insight:
                #doc.add_paragraph(f"üí° Insight contextuel: {contextual_insight}")
            
            # Recommandations automatiques
            if resultats.get('significatif_principal', False):
                doc.add_paragraph("üìã Recommandation: Cette relation significative m√©rite une attention "
                                "particuli√®re dans l'analyse et peut orienter les actions √† mettre en place.")
            else:
                doc.add_paragraph("üìã Note: L'absence de relation significative ne signifie pas n√©cessairement "
                                "l'absence de lien, mais sugg√®re que celui-ci n'est pas d√©tectable avec cet √©chantillon.")
            
            # Ajouter les graphiques
            clean_cible = "".join(c for c in var_cible if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_var = "".join(c for c in var_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_cible = clean_cible.replace(' ', '_')
            clean_var = clean_var.replace(' ', '_')
            
            if resultats['type_analyse'] == 'Num√©rique vs Cat√©gorielle':
                image_path = f"Sorties/Stat_Bivari√©es/boxplot_{clean_var}_par_{clean_cible}.png"
                add_image_to_doc(doc, image_path, "Distribution par groupe (Boxplot)", width=Inches(5))
                
            elif resultats['type_analyse'] == 'Cat√©gorielle vs Cat√©gorielle':
                image_path = f"Sorties/Stat_Bivari√©es/stacked_{clean_var}_selon_{clean_cible}.png"
                add_image_to_doc(doc, image_path, "R√©partition (Barres empil√©es)", width=Inches(5))
                
                #image_path = f"Sorties/Stat_Bivari√©es/heatmap_{clean_cible}_vs_{clean_var}.png"
                #add_image_to_doc(doc, image_path, "Carte de chaleur (Heatmap)", width=Inches(5))
                
            elif resultats['type_analyse'] == 'Num√©rique vs Num√©rique':
                image_path = f"Sorties/Stat_Bivari√©es/scatter_{clean_cible}_vs_{clean_var}.png"
                add_image_to_doc(doc, image_path, "Nuage de points", width=Inches(5))
            
            doc.add_paragraph()
    
    # Conclusion enrichie
    doc.add_page_break()
    doc.add_heading("üìã CONCLUSION ET RECOMMANDATIONS", level=1)
    
    conclusion_text = "Ce rapport pr√©sente une analyse statistique compl√®te et comment√©e des donn√©es fournies. "
    conclusion_text += f"L'analyse porte sur {df.shape[0]} observations et {df.shape[1]} variables, "
    conclusion_text += f"dont {len(numeric_vars)} variables num√©riques et {len(categorical_vars)} variables qualitatives.\n\n"
    
    if ponderation:
        conclusion_text += f"Les analyses ont √©t√© pond√©r√©es en utilisant la variable '{ponderation}'.\n\n"
    
    if resultats_bivariees:
        # Analyse des r√©sultats significatifs
        nb_significatifs = sum(1 for r in resultats_bivariees.values() if r.get('significatif_principal', False))
        conclusion_text += f"Les analyses bivari√©es ont permis d'√©tudier les relations entre la variable cible '{var_cible}' "
        conclusion_text += f"et {len(resultats_bivariees)} autres variables. "
        conclusion_text += f"{nb_significatifs} relations se sont r√©v√©l√©es statistiquement significatives.\n\n"
        
        if nb_significatifs > 0:
            conclusion_text += "**Points saillants identifi√©s:**\n"
            for var_name, resultats in resultats_bivariees.items():
                if resultats.get('significatif_principal', False):
                    conclusion_text += f"‚Ä¢ Relation significative entre {var_cible} et {var_name} "
                    conclusion_text += f"({resultats['type_analyse']})\n"
    
    # Recommandations g√©n√©rales bas√©es sur le contexte
    if commentator.study_theme or commentator.reference_context:
        conclusion_text += f"\n**Recommandations contextuelles:**\n"
        context = f"{commentator.study_theme} {commentator.reference_context}".lower()
        
        if any(word in context for word in ['satisfaction', 'qualit√©', 'service']):
            conclusion_text += "‚Ä¢ Approfondir l'analyse des variables li√©es √† la satisfaction pour identifier les leviers d'am√©lioration\n"
            conclusion_text += "‚Ä¢ Examiner les segments de client√®le r√©v√©l√©s par les analyses\n"
        elif any(word in context for word in ['performance', 'efficacit√©']):
            conclusion_text += "‚Ä¢ Investiguer les facteurs explicatifs des √©carts de performance observ√©s\n"
            conclusion_text += "‚Ä¢ Prioriser les actions sur les variables montrant les relations les plus fortes\n"
        else:
            conclusion_text += "‚Ä¢ Concentrer les efforts sur les relations statistiquement significatives identifi√©es\n"
            conclusion_text += "‚Ä¢ Consid√©rer des analyses compl√©mentaires pour les variables non significatives\n"
    
    conclusion_text += "\n\nLes commentaires automatiques int√©gr√©s facilitent l'interpr√©tation des r√©sultats "
    conclusion_text += "et orientent vers les conclusions les plus pertinentes pour votre contexte d'√©tude."
    
    doc.add_paragraph(conclusion_text)
    
    # Note technique enrichie
    doc.add_heading("üìå Note technique", level=2)
    tech_note = "Ce rapport a √©t√© g√©n√©r√© automatiquement par l'Analyseur Statistique Pro avec module de commentaires automatiques. "
    tech_note += "Les analyses statistiques ont √©t√© r√©alis√©es avec Python et les biblioth√®ques "
    tech_note += "pandas, scipy et numpy. Les graphiques ont √©t√© cr√©√©s avec plotly et streamlit-echarts. "
    tech_note += "Les commentaires automatiques sont bas√©s sur les bonnes pratiques d'interpr√©tation statistique "
    tech_note += "et adapt√©s au contexte fourni."
    
    doc.add_paragraph(tech_note)
    
    return doc

# Fonction pour cr√©er le rapport Excel des analyses bivari√©es
def create_bivariate_excel_report(resultats_analyses, var_cible, ponderation, palette_name, selected_sheet=None):
    """Cr√©e un rapport Excel complet des analyses bivari√©es"""
    excel_buffer = io.BytesIO()
    
    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
        
        # Feuille de synth√®se
        synthese_data = []
        for var_name, resultats in resultats_analyses.items():
            synthese_data.append({
                'Variable': var_name,
                'Type d\'analyse': resultats['type_analyse'],
                'Nombre d\'observations': resultats['n_observations'],
                'Test principal': resultats.get('test_principal', 'N/A'),
                'P-value': resultats.get('p_value_principal', 'N/A'),
                'Significatif': resultats.get('significatif_principal', 'N/A')
            })
        
        synthese_df = pd.DataFrame(synthese_data)
        synthese_df.to_excel(writer, sheet_name='00_Synthese', index=False)
        
        # Informations g√©n√©rales
        info_df = pd.DataFrame({
            'Param√®tre': ['Variable cible', 'Feuille Excel', 'Pond√©ration', 'Palette de couleurs', 'Date d\'analyse', 'Nombre d\'analyses'],
            'Valeur': [var_cible, selected_sheet if selected_sheet else 'N/A (CSV)', 
                      ponderation if ponderation else 'Aucune', palette_name, 
                      datetime.now().strftime('%Y-%m-%d %H:%M'), len(resultats_analyses)]
        })
        info_df.to_excel(writer, sheet_name='00_Informations', index=False)
        
        # Feuille pour chaque analyse
        for i, (var_name, resultats) in enumerate(resultats_analyses.items(), 1):
            sheet_name = f"{i:02d}_{var_name[:25]}"  # Limiter la longueur du nom
            
            # √âcrire les diff√©rents tableaux sur la m√™me feuille
            current_row = 0
            
            # Titre de l'analyse
            title_df = pd.DataFrame({
                'Analyse': [f"{var_cible} √ó {var_name}"],
                'Type': [resultats['type_analyse']],
                'Observations': [resultats['n_observations']]
            })
            title_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False)
            current_row += 3
            
            # Tableau principal (crosstab ou stats descriptives)
            if 'tableau_principal' in resultats:
                # Ajouter un en-t√™te
                header_df = pd.DataFrame({'': ['TABLEAU PRINCIPAL']})
                header_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False, header=False)
                current_row += 1
                
                resultats['tableau_principal'].to_excel(writer, sheet_name=sheet_name, startrow=current_row)
                current_row += len(resultats['tableau_principal']) + 3
            
            # Tests statistiques
            if 'tests' in resultats and resultats['tests']:
                header_df = pd.DataFrame({'': ['TESTS STATISTIQUES']})
                header_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False, header=False)
                current_row += 1
                
                tests_df = pd.DataFrame(resultats['tests'])
                tests_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False)
                current_row += len(tests_df) + 3
            
            # Tableau suppl√©mentaire (ex: pourcentages pour les variables cat√©gorielles)
            if 'tableau_secondaire' in resultats:
                header_df = pd.DataFrame({'': ['TABLEAU SECONDAIRE']})
                header_df.to_excel(writer, sheet_name=sheet_name, startrow=current_row, index=False, header=False)
                current_row += 1
                
                resultats['tableau_secondaire'].to_excel(writer, sheet_name=sheet_name, startrow=current_row)
                current_row += len(resultats['tableau_secondaire']) + 3
    
    return excel_buffer

# Interface utilisateur pour la configuration des commentaires
def add_comments_configuration_ui():
    """Interface pour configurer les commentaires automatiques"""
    st.header("üí¨ Commentaires automatiques")
    
    # Option pour activer/d√©sactiver les commentaires
    enable_comments = st.checkbox("Activer les commentaires automatiques", value=True,
                                help="Les rapports Word incluront des interpr√©tations automatiques")
    
    if enable_comments:
        # Th√®me de l'√©tude
        study_theme = st.text_area(
            "üéØ Th√®me de l'√©tude (optionnel):",
            placeholder="Ex: Enqu√™te de satisfaction client, Analyse de performance, √âtude d√©mographique...",
            help="D√©crivez le contexte de votre √©tude pour des commentaires plus pertinents"
        )
        
        # Document de r√©f√©rence
        st.write("üìÑ Document de r√©f√©rence (optionnel):")
        reference_doc = st.file_uploader(
            "Chargez un document de contexte",
            type=['txt', 'docx'],
            help="Document contenant le contexte, les objectifs ou la m√©thodologie de l'√©tude"
        )
        
        # Analyse du document de r√©f√©rence
        reference_context = ""
        if reference_doc is not None:
            with st.spinner("Analyse du document de r√©f√©rence..."):
                reference_context = analyze_reference_document(reference_doc)
                if reference_context:
                    st.success("‚úÖ Document analys√©")
                    with st.expander("üëÄ Aper√ßu du contexte extrait"):
                        st.write(reference_context[:300] + "..." if len(reference_context) > 300 else reference_context)
        
        # Niveau de d√©tail des commentaires
        comment_level = st.selectbox(
            "üìä Niveau de d√©tail des commentaires:",
            ["Standard", "D√©taill√©", "Expert"],
            help="Standard: commentaires essentiels, D√©taill√©: analyses approfondies, Expert: insights techniques"
        )
        
        # Cr√©er le commentator
        commentator = StatisticalCommentator(study_theme, reference_context)
        
        return enable_comments, commentator, comment_level
    else:
        return False, None, "Standard"

def analyze_numeric_vs_categorical(df_clean, var_cible, var_num, ponderation, save_folder, colors):
    """Analyse crois√©e variable cat√©gorielle vs num√©rique avec affichage complet et retour de donn√©es"""
    
    # Dictionnaire pour stocker les r√©sultats
    resultats = {
        'type_analyse': 'Num√©rique vs Cat√©gorielle',
        'n_observations': len(df_clean),
        'tests': [],
        'tableau_principal': None,
        'test_principal': None,
        'p_value_principal': None,
        'significatif_principal': None
    }
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.write("üìã **Statistiques descriptives par groupe:**")
        
        # Tableau des statistiques descriptives par groupe
        if ponderation is None:
            tableau_desc = df_clean.groupby(var_cible)[var_num].agg([
                'count', 'mean', 'std', 'min', 'median', 'max'
            ]).round(3)
        else:
            # Version simplifi√©e pour la pond√©ration
            stats_list = []
            for groupe_name in df_clean[var_cible].unique():
                groupe_data = df_clean[df_clean[var_cible] == groupe_name]
                values = groupe_data[var_num]
                weights = groupe_data[ponderation]
                
                if len(values) > 0:
                    weighted_mean = np.average(values, weights=weights)
                    stats_list.append({
                        'count': len(values),
                        'mean': weighted_mean,
                        'min': values.min(),
                        'median': np.median(values),  # Approximation
                        'max': values.max()
                    })
                else:
                    stats_list.append({
                        'count': 0, 'mean': np.nan, 'min': np.nan, 
                        'median': np.nan, 'max': np.nan
                    })
            
            tableau_desc = pd.DataFrame(stats_list, index=sorted(df_clean[var_cible].unique())).round(3)
        
        resultats['tableau_principal'] = tableau_desc
        st.dataframe(tableau_desc, use_container_width=True)
        
        # Tests statistiques
        st.write("üß™ **Tests statistiques:**")
        groupes = df_clean.groupby(var_cible)[var_num]
        groupes_data = [groupe_data.values for _, groupe_data in groupes if len(groupe_data) >= 3]
        
        if len(groupes_data) >= 2:
            try:
                if len(groupes_data) == 2:
                    stat, p_value = ttest_ind(groupes_data[0], groupes_data[1])
                    test_name = "Test t de Student"
                else:
                    stat, p_value = f_oneway(*groupes_data)
                    test_name = "ANOVA (Test F)"
                
                # Stockage du test principal
                resultats['test_principal'] = test_name
                resultats['p_value_principal'] = round(p_value, 4)
                resultats['significatif_principal'] = p_value < 0.05
                
                st.write(f"‚Ä¢ **{test_name}:** {stat:.4f}")
                st.write(f"‚Ä¢ **p-value:** {p_value:.4f}")
                st.write(f"‚Ä¢ **R√©sultat:** {'Diff√©rence significative' if p_value < 0.05 else 'Pas de diff√©rence significative'}")
                
                # Ajouter aux tests
                resultats['tests'].append({
                    'Test': test_name,
                    'Statistique': round(stat, 4),
                    'p-value': round(p_value, 4),
                    'Significatif': p_value < 0.05,
                    'Interpr√©tation': 'Diff√©rence significative' if p_value < 0.05 else 'Pas de diff√©rence significative'
                })
                
                # Test de normalit√© pour chaque groupe
                st.write("‚Ä¢ **Tests de normalit√©:**")
                tests_normalite = []
                for groupe_name, groupe_data in groupes:
                    if len(groupe_data) >= 3:
                        if len(groupe_data) < 50:
                            stat_norm, p_norm = shapiro(groupe_data)
                            test_norm = "Shapiro-Wilk"
                        else:
                            stat_norm, p_norm = normaltest(groupe_data)
                            test_norm = "D'Agostino-Pearson"
                        
                        est_normal = p_norm > 0.05
                        st.write(f"  - {groupe_name}: {test_norm} p={p_norm:.3f} {'‚úÖ Normal' if est_normal else '‚ùå Non-normal'}")
                        
                        tests_normalite.append({
                            'Test': f"{test_norm} ({groupe_name})",
                            'Statistique': round(stat_norm, 4),
                            'p-value': round(p_norm, 4),
                            'Significatif': not est_normal,
                            'Interpr√©tation': 'Normal' if est_normal else 'Non-normal'
                        })
                
                resultats['tests'].extend(tests_normalite)
                        
            except Exception as e:
                st.write(f"‚Ä¢ Erreur dans les tests: {str(e)}")
                resultats['tests'].append({
                    'Test': 'Erreur',
                    'Statistique': 'N/A',
                    'p-value': 'N/A',
                    'Significatif': False,
                    'Interpr√©tation': str(e)
                })
        else:
            st.write("‚Ä¢ Pas assez de groupes pour les tests")
            resultats['tests'].append({
                'Test': 'Impossible',
                'Statistique': 'N/A',
                'p-value': 'N/A',
                'Significatif': False,
                'Interpr√©tation': 'Pas assez de groupes'
            })
    
    with col2:
        st.write("üìä **Graphiques de comparaison:**")
        
        # Affichage des graphiques dans la m√™me colonne
        create_boxplot_echarts(df_clean, var_cible, var_num, save_folder, colors)
    
    return resultats

def analyze_categorical_vs_categorical(df_clean, var_cible, var_cat, ponderation, save_folder, colors):
    """Analyse crois√©e entre deux variables cat√©gorielles avec affichage complet et retour de donn√©es"""
    
    # Dictionnaire pour stocker les r√©sultats
    resultats = {
        'type_analyse': 'Cat√©gorielle vs Cat√©gorielle',
        'n_observations': len(df_clean),
        'tests': [],
        'tableau_principal': None,
        'tableau_secondaire': None,
        'test_principal': None,
        'p_value_principal': None,
        'significatif_principal': None
    }
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.write("üìã **Tableau crois√©:**")
        
        # Tableau crois√©
        if ponderation is None:
            tab_fi = pd.crosstab(df_clean[var_cible], df_clean[var_cat], margins=True)
            tab_pct = pd.crosstab(df_clean[var_cible], df_clean[var_cat], normalize='index') * 100
        else:
            tab_fi = pd.crosstab(
                df_clean[var_cible], df_clean[var_cat], 
                values=df_clean[ponderation], aggfunc='sum', margins=True
            ).fillna(0).round(1)
            tab_pct = pd.crosstab(
                df_clean[var_cible], df_clean[var_cat], 
                values=df_clean[ponderation], aggfunc='sum', normalize='index'
            ).fillna(0) * 100
        
        resultats['tableau_principal'] = tab_fi
        resultats['tableau_secondaire'] = tab_pct.round(2)
        
        st.dataframe(tab_fi, use_container_width=True)
        
        st.write("üìä **Pourcentages par ligne:**")
        st.dataframe(tab_pct.round(2), use_container_width=True)
        
        # Test du Chi2
        st.write("üß™ **Test d'ind√©pendance (Chi2):**")
        try:
            if ponderation is None:
                observed = pd.crosstab(df_clean[var_cible], df_clean[var_cat])
            else:
                observed = pd.crosstab(
                    df_clean[var_cible], df_clean[var_cat], 
                    values=df_clean[ponderation], aggfunc='sum'
                ).fillna(0)
            
            chi2_stat, p_value, dof, expected = chi2_contingency(observed)
            
            # Stockage du test principal
            resultats['test_principal'] = "Test du Chi2"
            resultats['p_value_principal'] = round(p_value, 4)
            resultats['significatif_principal'] = p_value < 0.05
            
            st.write(f"‚Ä¢ **Chi2:** {chi2_stat:.4f}")
            st.write(f"‚Ä¢ **p-value:** {p_value:.4f}")
            st.write(f"‚Ä¢ **Degr√©s de libert√©:** {dof}")
            st.write(f"‚Ä¢ **R√©sultat:** {'Association significative' if p_value < 0.05 else 'Association non significative'}")
            
            # Crit√®res de validit√©
            expected_min = expected.min()
            cells_less_than_5 = (expected < 5).sum().sum()
            total_cells = expected.size
            percent_less_than_5 = (cells_less_than_5 / total_cells) * 100
            
            st.write("‚Ä¢ **Crit√®res de validit√©:**")
            st.write(f"  - Effectif th√©orique minimum: {expected_min:.2f}")
            st.write(f"  - Cellules < 5: {cells_less_than_5}/{total_cells} ({percent_less_than_5:.1f}%)")
            test_valide = expected_min >= 1 and percent_less_than_5 <= 20
            st.write(f"  - Test valide: {'‚úÖ Oui' if test_valide else '‚ùå Non'}")
            
            # Ajouter le test principal
            resultats['tests'].append({
                'Test': 'Test du Chi2',
                'Statistique': round(chi2_stat, 4),
                'p-value': round(p_value, 4),
                'Degr√©s de libert√©': dof,
                'Significatif': p_value < 0.05,
                'Interpr√©tation': 'Association significative' if p_value < 0.05 else 'Association non significative'
            })
            
            # Ajouter les crit√®res de validit√©
            resultats['tests'].append({
                'Test': 'Crit√®res de validit√©',
                'Effectif min th√©orique': round(expected_min, 2),
                'Cellules < 5': f"{cells_less_than_5}/{total_cells}",
                'Pourcentage < 5': f"{percent_less_than_5:.1f}%",
                'Test valide': test_valide,
                'Interpr√©tation': 'Test valide' if test_valide else 'Test non valide'
            })
            
            # Coefficient de Cram√©r's V
            if chi2_stat > 0:
                n = observed.sum().sum()
                cramers_v = np.sqrt(chi2_stat / (n * (min(observed.shape) - 1)))
                st.write(f"‚Ä¢ **Cram√©r's V:** {cramers_v:.4f}")
                if cramers_v < 0.1:
                    interpretation = "Association tr√®s faible"
                elif cramers_v < 0.3:
                    interpretation = "Association faible"
                elif cramers_v < 0.5:
                    interpretation = "Association mod√©r√©e"
                else:
                    interpretation = "Association forte"
                st.write(f"‚Ä¢ **Interpr√©tation:** {interpretation}")
                
                resultats['tests'].append({
                    'Test': "Cram√©r's V",
                    'Statistique': round(cramers_v, 4),
                    'Seuils': '< 0.1: tr√®s faible, < 0.3: faible, < 0.5: mod√©r√©e, ‚â• 0.5: forte',
                    'Interpr√©tation': interpretation
                })
            
        except Exception as e:
            st.write(f"‚Ä¢ Erreur dans le test Chi2: {str(e)}")
            resultats['tests'].append({
                'Test': 'Erreur Chi2',
                'Erreur': str(e),
                'Interpr√©tation': 'Test impossible'
            })
    
    with col2:
        st.write("üìä **Visualisations:**")
        
        # Affichage des graphiques
        create_stacked_bar_echarts(df_clean, var_cible, var_cat, save_folder, colors)
        create_heatmap_echarts(df_clean, var_cible, var_cat, save_folder, colors)
    
    return resultats

def analyze_numeric_vs_numeric(df_clean, var_cible, var_num, ponderation, save_folder, colors):
    """Analyse de corr√©lation entre deux variables num√©riques avec affichage complet et retour de donn√©es"""
    
    # Dictionnaire pour stocker les r√©sultats
    resultats = {
        'type_analyse': 'Num√©rique vs Num√©rique',
        'n_observations': len(df_clean),
        'tests': [],
        'tableau_principal': None,
        'test_principal': None,
        'p_value_principal': None,
        'significatif_principal': None
    }
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.write("üìä **Analyse de corr√©lation:**")
        
        # Corr√©lation
        correlation = df_clean[var_cible].corr(df_clean[var_num])
        st.write(f"‚Ä¢ **Corr√©lation de Pearson:** {correlation:.4f}")
        
        # Interpr√©tation de la force
        if abs(correlation) > 0.7:
            interpretation = "Forte"
        elif abs(correlation) > 0.5:
            interpretation = "Mod√©r√©e"
        elif abs(correlation) > 0.3:
            interpretation = "Faible"
        else:
            interpretation = "Tr√®s faible"
        
        st.write(f"‚Ä¢ **Intensit√©:** {interpretation}")
        st.write(f"‚Ä¢ **Direction:** {'Positive' if correlation > 0 else 'N√©gative'}")
        
        # Test de significativit√©
        try:
            from scipy.stats import pearsonr
            _, p_value = pearsonr(df_clean[var_cible], df_clean[var_num])
            
            # Stockage du test principal
            resultats['test_principal'] = "Corr√©lation de Pearson"
            resultats['p_value_principal'] = round(p_value, 4)
            resultats['significatif_principal'] = p_value < 0.05
            
            st.write(f"‚Ä¢ **p-value:** {p_value:.4f}")
            st.write(f"‚Ä¢ **Significativit√©:** {'Significative' if p_value < 0.05 else 'Non significative'}")
            
            # Coefficient de d√©termination
            r_squared = correlation ** 2
            st.write(f"‚Ä¢ **R¬≤ (coefficient de d√©termination):** {r_squared:.4f}")
            st.write(f"‚Ä¢ **Variance expliqu√©e:** {r_squared*100:.1f}%")
            
            # Ajouter aux tests
            resultats['tests'].append({
                'Test': 'Corr√©lation de Pearson',
                'Coefficient': round(correlation, 4),
                'p-value': round(p_value, 4),
                'R¬≤': round(r_squared, 4),
                'Variance expliqu√©e (%)': round(r_squared*100, 1),
                'Significatif': p_value < 0.05,
                'Intensit√©': interpretation,
                'Direction': 'Positive' if correlation > 0 else 'N√©gative',
                'Interpr√©tation': f"Corr√©lation {interpretation.lower()} {'significative' if p_value < 0.05 else 'non significative'}"
            })
            
        except Exception as e:
            st.write(f"‚Ä¢ Erreur dans le test de corr√©lation: {str(e)}")
            resultats['tests'].append({
                'Test': 'Erreur corr√©lation',
                'Erreur': str(e)
            })
        
        # Tableau de contingence des quartiles
        st.write("üìã **R√©partition par quartiles:**")
        try:
            quartiles_x = pd.qcut(df_clean[var_cible], 4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')
            quartiles_y = pd.qcut(df_clean[var_num], 4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')
            quartiles_crosstab = pd.crosstab(quartiles_x, quartiles_y)
            resultats['tableau_principal'] = quartiles_crosstab
            st.dataframe(quartiles_crosstab, use_container_width=True)
        except Exception as e:
            st.write(f"Impossible de cr√©er les quartiles: {str(e)}")
            resultats['tableau_principal'] = pd.DataFrame({'Erreur': [str(e)]})
    
    with col2:
        st.write("üìä **Nuage de points:**")
        
        # Nuage de points avec ECharts
        data = [[float(x), float(y)] for x, y in zip(df_clean[var_cible], df_clean[var_num]) if not (pd.isna(x) or pd.isna(y))]
        
        option = {
            "title": {
                "text": f"üìà {var_cible} vs {var_num}",
                "left": "center",
                "textStyle": {"fontSize": 16, "color": "#2E4057"}
            },
            "tooltip": {"trigger": "item"},
            "xAxis": {
                "type": "value",
                "name": var_cible,
                "axisLabel": {"fontSize": 11}
            },
            "yAxis": {
                "type": "value",
                "name": var_num,
                "axisLabel": {"fontSize": 11}
            },
            "series": [
                {
                    "type": "scatter",
                    "data": data,
                    "itemStyle": {"color": colors[0]},
                    "symbolSize": 8
                }
            ],
            "grid": {
                "left": "15%",
                "right": "10%",
                "bottom": "15%",
                "top": "15%"
            }
        }
        
        st_echarts(options=option, height="400px", key=f"scatter_{var_cible}_{var_num}")
        
        # Export du nuage de points
        if save_folder:
            fig = px.scatter(df_clean, x=var_cible, y=var_num, trendline="ols",
                           title=f"üìà Nuage de points: {var_cible} vs {var_num}")
            fig.update_layout(
                title={'x': 0.5, 'xanchor': 'center', 'font': {'size': 16, 'color': '#2E4057'}},
                height=500, font=dict(family="Arial, sans-serif"),
                paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)'
            )
            
            clean_cible = "".join(c for c in var_cible if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_num = "".join(c for c in var_num if c.isalnum() or c in (' ', '-', '_')).rstrip()
            clean_cible = clean_cible.replace(' ', '_')
            clean_num = clean_num.replace(' ', '_')
            save_path = f"{save_folder}/scatter_{clean_cible}_vs_{clean_num}.png"
            
            try:
                pio.write_image(fig, save_path, width=800, height=500)
            except Exception as e:
                st.warning(f"Impossible de sauvegarder le graphique: {str(e)}")
    
    return resultats

# Interface principale
def main():
    # Cr√©er les dossiers de sortie
    create_output_folders()
    
    # Titre principal
    st.markdown('<div class="main-header">üìä Analyseur Statistique Pro</div>', unsafe_allow_html=True)
    
    # Sidebar pour le chargement des donn√©es
    with st.sidebar:
        st.header("üîß Configuration")
        
        # Configuration des commentaires automatiques
        enable_comments, commentator, comment_level = add_comments_configuration_ui()
        
        # Upload de fichier
        uploaded_file = st.file_uploader(
            "üìÅ Charger vos donn√©es",
            type=['csv', 'xlsx', 'xls'],
            help="Formats support√©s: CSV, Excel (.xlsx, .xls)"
        )
        
        # Variables globales pour stocker les donn√©es d'analyse
        if 'analyses_data' not in st.session_state:
            st.session_state.analyses_data = {
                'numeric_vars': [],
                'categorical_vars': [],
                'resultats_bivariees': None,
                'var_cible': None,
                'df': None,
                'ponderation': None,
                'palette_name': None,
                'selected_sheet': None
            }
        
        # Variables par d√©faut
        df = None
        selected_sheet = None
        ponderation = None
        palette_name = "D√©faut (Verte/Orange)"
        selected_colors = COLOR_PALETTES[palette_name]
        show_missing = True
        show_correlation = True
        numeric_vars = []
        categorical_vars = []
        
        if uploaded_file is not None:
            # Gestion sp√©ciale pour les fichiers Excel avec plusieurs feuilles
            if uploaded_file.name.endswith(('.xlsx', '.xls')):
                # R√©cup√©rer la liste des feuilles
                excel_sheets = get_excel_sheets(uploaded_file)
                
                if len(excel_sheets) > 1:
                    st.subheader("üìã S√©lection de la feuille Excel")
                    st.info(f"üìä Ce fichier Excel contient **{len(excel_sheets)} feuilles**. S√©lectionnez celle qui contient vos donn√©es √† analyser.")
                    
                    selected_sheet = st.selectbox(
                        "Choisissez la feuille √† analyser:",
                        excel_sheets,
                        help="Chaque feuille peut contenir des donn√©es diff√©rentes"
                    )
                    
                    # Aper√ßu des feuilles disponibles
                    with st.expander("üëÄ Aper√ßu des feuilles disponibles"):
                        for i, sheet in enumerate(excel_sheets, 1):
                            try:
                                # Lire quelques lignes pour aper√ßu
                                preview_df = pd.read_excel(uploaded_file, sheet_name=sheet, nrows=3)
                                st.write(f"**{i}. {sheet}** ({preview_df.shape[0]}+ lignes √ó {preview_df.shape[1]} colonnes)")
                                if len(preview_df.columns) <= 10:  # Afficher seulement si pas trop de colonnes
                                    st.write(f"Colonnes: {', '.join(preview_df.columns[:10])}")
                                else:
                                    st.write(f"Colonnes: {', '.join(preview_df.columns[:10])}... (+{len(preview_df.columns)-10} autres)")
                            except Exception as e:
                                st.write(f"**{i}. {sheet}** (Erreur: {str(e)})")
                else:
                    selected_sheet = excel_sheets[0] if excel_sheets else None
            
            # Chargement des donn√©es
            if uploaded_file.name.endswith('.csv') or selected_sheet is not None:
                with st.spinner("Chargement des donn√©es..."):
                    df = load_data(uploaded_file, selected_sheet)
            
            if df is not None:
                st.success(f"‚úÖ {df.shape[0]} lignes, {df.shape[1]} colonnes")
                if selected_sheet:
                    st.info(f"üìã Feuille charg√©e: **{selected_sheet}**")
                
                # D√©finir les types de variables
                numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
                categorical_vars = df.select_dtypes(include=['object', 'category']).columns.tolist()
                
                # Mettre √† jour les donn√©es dans le session_state
                st.session_state.analyses_data['df'] = df
                st.session_state.analyses_data['selected_sheet'] = selected_sheet
                
                # S√©lection de la palette de couleurs
                st.subheader("üé® Palette de couleurs")
                
                # S√©lecteur de palette
                palette_name = st.selectbox(
                    "Choisissez votre palette:",
                    list(COLOR_PALETTES.keys()),
                    index=0,
                    help="La palette s√©lectionn√©e sera utilis√©e pour tous les graphiques"
                )
                
                # Aper√ßu de la palette s√©lectionn√©e
                selected_colors = COLOR_PALETTES[palette_name]
                show_palette_preview("Aper√ßu", selected_colors)
                
                # Mettre √† jour la palette dans le session_state
                st.session_state.analyses_data['palette_name'] = palette_name
                
                # S√©lection de la pond√©ration
                st.subheader("‚öñÔ∏è Pond√©ration (optionnel)")
                ponderation = st.selectbox(
                    "Variable de pond√©ration:",
                    ['Aucune'] + numeric_vars,
                    help="S√©lectionnez une variable num√©rique pour pond√©rer les analyses"
                )
                ponderation = None if ponderation == 'Aucune' else ponderation
                
                # Retirer la variable de pond√©ration des variables √† analyser
                if ponderation and ponderation in numeric_vars:
                    numeric_vars.remove(ponderation)
                
                # Mettre √† jour les donn√©es dans le session_state
                st.session_state.analyses_data['numeric_vars'] = numeric_vars
                st.session_state.analyses_data['categorical_vars'] = categorical_vars
                st.session_state.analyses_data['ponderation'] = ponderation
                
                # Options d'affichage
                st.subheader("üéõÔ∏è Options d'affichage")
                show_missing = st.checkbox("Afficher l'analyse des donn√©es manquantes", value=True)
                show_correlation = st.checkbox("Afficher la matrice de corr√©lation", value=True)
    
    # Contenu principal
    if uploaded_file is not None and df is not None:
        # R√©cup√©ration de la palette s√©lectionn√©e
        selected_colors = COLOR_PALETTES[palette_name]
        
        # Onglets principaux
        tab1, tab2, tab3, tab4 = st.tabs(["üìã Aper√ßu des donn√©es", "üìä Analyses univari√©es", "üîó Analyses bivari√©es", "üì• Exports"])
        
        with tab1:
            st.markdown('<div class="sub-header">üìã Aper√ßu des donn√©es</div>', unsafe_allow_html=True)
            
            # Informations g√©n√©rales
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üìè Lignes", df.shape[0])
            with col2:
                st.metric("üìä Colonnes", df.shape[1])
            with col3:
                memory_mb = df.memory_usage(deep=True).sum() / 1024**2
                st.metric("üíæ M√©moire", f"{memory_mb:.1f} MB")
            with col4:
                missing_pct = (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100
                st.metric("‚ùå Manquantes", f"{missing_pct:.1f}%")
            
            # Aper√ßu du dataset
            st.subheader("üëÄ Aper√ßu du dataset")
            st.dataframe(df.head(10), use_container_width=True)
            
            # Types de variables
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("üî¢ Variables num√©riques")
                st.write(f"**{len(numeric_vars)} variables:** {', '.join(numeric_vars) if numeric_vars else 'Aucune'}")
            
            with col2:
                st.subheader("üìù Variables qualitatives")
                st.write(f"**{len(categorical_vars)} variables:** {', '.join(categorical_vars) if categorical_vars else 'Aucune'}")
            
            # Analyse des donn√©es manquantes
            if show_missing:
                st.subheader("üö® Analyse des donn√©es manquantes")
                missing_data = df.isnull().sum()
                missing_pct = (missing_data / len(df)) * 100
                missing_df = pd.DataFrame({
                    'Variable': missing_data.index,
                    'Valeurs manquantes': missing_data.values,
                    'Pourcentage (%)': missing_pct.values
                }).query('`Valeurs manquantes` > 0').sort_values('Valeurs manquantes', ascending=False)
                
                if len(missing_df) > 0:
                    st.dataframe(missing_df, use_container_width=True)
                    
                    # Graphique des donn√©es manquantes
                    if len(missing_df) <= 20:  # Limiter pour la lisibilit√©
                        value_counts = missing_df.set_index('Variable')['Pourcentage (%)']
                        create_bar_chart_echarts(value_counts, "Donn√©es manquantes (%)", None, selected_colors, 0)
                else:
                    st.success("‚úÖ Aucune donn√©e manquante d√©tect√©e!")
            
            # Matrice de corr√©lation
            if show_correlation and len(numeric_vars) > 1:
                st.subheader("üîó Matrice de corr√©lation")
                corr_matrix = df[numeric_vars].corr()
                
                # Graphique avec ECharts
                data = []
                for i, row_name in enumerate(corr_matrix.index):
                    for j, col_name in enumerate(corr_matrix.columns):
                        data.append([j, i, round(corr_matrix.loc[row_name, col_name], 3)])
                
                option = {
                    "title": {
                        "text": "üîó Matrice de corr√©lation",
                        "left": "center",
                        "textStyle": {"fontSize": 16}
                    },
                    "tooltip": {"position": "top"},
                    "grid": {"height": "50%", "top": "15%"},
                    "xAxis": {
                        "type": "category",
                        "data": list(corr_matrix.columns),
                        "splitArea": {"show": True}
                    },
                    "yAxis": {
                        "type": "category",
                        "data": list(corr_matrix.index),
                        "splitArea": {"show": True}
                    },
                    "visualMap": {
                        "min": -1,
                        "max": 1,
                        "calculable": True,
                        "orient": "horizontal",
                        "left": "center",
                        "bottom": "15%",
                        "inRange": {"color": ["#313695", "#f7f7f7", "#a50026"]}
                    },
                    "series": [
                        {
                            "name": "Corr√©lation",
                            "type": "heatmap",
                            "data": data,
                            "label": {"show": True}
                        }
                    ]
                }
                
                st_echarts(options=option, height="600px", key="correlation_matrix")
        
        with tab2:
            st.markdown('<div class="sub-header">üìä Analyses statistiques univari√©es</div>', unsafe_allow_html=True)
            
            # Bouton pour lancer l'analyse
            if st.button("üöÄ Lancer l'analyse univari√©e", type="primary", use_container_width=True):
                
                save_folder = "Sorties/Stat_Univari√©es"
                
                # Analyse des variables num√©riques
                if numeric_vars:
                    st.subheader("üî¢ Variables num√©riques")
                    
                    with st.spinner("Analyse des variables num√©riques..."):
                        stats_table = analyze_numeric_variables(df, numeric_vars, ponderation)
                    
                    st.dataframe(stats_table, use_container_width=True)
                    
                    # Export Excel des statistiques
                    excel_buffer = io.BytesIO()
                    stats_table.to_excel(excel_buffer, index=True)
                    st.download_button(
                        label="üì• T√©l√©charger les statistiques (Excel)",
                        data=excel_buffer.getvalue(),
                        file_name=f"stats_numeriques_{'pondere' if ponderation else 'simple'}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                
                # Analyse des variables qualitatives
                if categorical_vars:
                    st.subheader("üìù Variables qualitatives")
                    
                    for i, var in enumerate(categorical_vars):
                        with st.container():
                            st.markdown(f'<div class="analysis-container">', unsafe_allow_html=True)
                            st.write(f"**üìä Variable: {var}**")
                            
                            # Calcul des fr√©quences
                            if ponderation is None:
                                value_counts = df[var].value_counts()
                                total = value_counts.sum()
                            else:
                                mask_valid = df[var].notna() & df[ponderation].notna()
                                if mask_valid.sum() > 0:
                                    value_counts = df[mask_valid].groupby(var)[ponderation].sum().sort_values(ascending=False)
                                    total = value_counts.sum()
                                else:
                                    st.warning(f"Aucune donn√©e valide pour {var}")
                                    continue
                            
                            # Tableau de fr√©quences
                            freq_table = pd.DataFrame({
                                'Effectif': value_counts,
                                'Fr√©quence (%)': (value_counts / total * 100).round(2)
                            })
                            
                            col1, col2 = st.columns([1, 2])
                            with col1:
                                st.dataframe(freq_table.head(10))
                                
                                # Informations sur la variable
                                n_categories = len(value_counts)
                                missing_count = df[var].isnull().sum()
                                st.write(f"‚Ä¢ **Modalit√©s:** {n_categories}")
                                st.write(f"‚Ä¢ **Manquantes:** {missing_count} ({(missing_count/len(df)*100):.1f}%)")
                                if ponderation:
                                    st.write(f"‚Ä¢ **Effectif pond√©r√©:** {total:.0f}")
                            
                            with col2:
                                # Logique de choix du graphique selon le nombre de modalit√©s
                                if n_categories <= 3:
                                    # Graphique en secteurs (alternance disque/anneau)
                                    create_pie_chart_echarts(value_counts, var, save_folder, selected_colors, i)
                                else:
                                    # Graphique en barres (alternance vertical/horizontal)
                                    create_bar_chart_echarts(value_counts, var, save_folder, selected_colors, i)
                            
                            st.markdown('</div>', unsafe_allow_html=True)
        
        with tab3:
            st.markdown('<div class="sub-header">üîó Analyses statistiques bivari√©es</div>', unsafe_allow_html=True)
            
            # S√©lection des variables
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("üéØ Variable cible")
                all_vars = list(df.columns)
                if ponderation and ponderation in all_vars:
                    all_vars.remove(ponderation)
                
                var_cible = st.selectbox(
                    "S√©lectionnez la variable cible:",
                    all_vars,
                    help="Variable avec laquelle croiser toutes les autres"
                )
            
            with col2:
                st.subheader("üìã Variables √† croiser")
                autres_vars = [col for col in all_vars if col != var_cible]
                variables_selectionnees = st.multiselect(
                    "S√©lectionnez les variables (laisser vide pour toutes):",
                    autres_vars,
                    help="Si aucune variable n'est s√©lectionn√©e, toutes seront analys√©es"
                )
                
                if not variables_selectionnees:
                    variables_selectionnees = autres_vars
            
            # Bouton pour lancer l'analyse
            if st.button("üöÄ Lancer l'analyse bivari√©e", type="primary", use_container_width=True):
                if var_cible and variables_selectionnees:
                    
                    save_folder = "Sorties/Stat_Bivari√©es"
                    
                    # Dictionnaire pour stocker tous les r√©sultats d'analyse
                    resultats_analyses = {}
                    
                    # Mettre √† jour la variable cible dans le session_state
                    st.session_state.analyses_data['var_cible'] = var_cible
                    
                    # Progress bar
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, var in enumerate(variables_selectionnees):
                        status_text.text(f"Analyse de {var_cible} vs {var}...")
                        progress_bar.progress((i + 1) / len(variables_selectionnees))
                        
                        with st.container():
                            st.markdown(f'<div class="analysis-container">', unsafe_allow_html=True)
                            st.markdown(f"### üîç {var_cible} ‚úñÔ∏è {var}")
                            
                            # Nettoyage des donn√©es
                            cols_to_use = [var_cible, var]
                            if ponderation:
                                cols_to_use.append(ponderation)
                            
                            df_clean = df[cols_to_use].dropna()
                            
                            if len(df_clean) == 0:
                                st.warning(f"Aucune donn√©e valide pour l'analyse {var_cible} vs {var}")
                                continue
                            
                            is_target_numeric = df[var_cible].dtype in ['int64', 'float64', 'int32', 'float32']
                            is_var_numeric = df[var].dtype in ['int64', 'float64', 'int32', 'float32']
                            
                            if is_var_numeric and not is_target_numeric:
                                # Variable num√©rique vs cat√©gorielle
                                resultats_analyses[var] = analyze_numeric_vs_categorical(df_clean, var_cible, var, ponderation, save_folder, selected_colors)
                                
                            elif not is_var_numeric and not is_target_numeric:
                                # Deux variables cat√©gorielles
                                resultats_analyses[var] = analyze_categorical_vs_categorical(df_clean, var_cible, var, ponderation, save_folder, selected_colors)
                                
                            elif is_var_numeric and is_target_numeric:
                                # Deux variables num√©riques - corr√©lation
                                resultats_analyses[var] = analyze_numeric_vs_numeric(df_clean, var_cible, var, ponderation, save_folder, selected_colors)
                            
                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    status_text.text("‚úÖ Analyse termin√©e!")
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Stocker les r√©sultats dans le session_state
                    st.session_state.analyses_data['resultats_bivariees'] = resultats_analyses
                    
                    # Boutons d'export
                    if resultats_analyses:
                        st.subheader("üì• Export des r√©sultats")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if st.button("üìä T√©l√©charger Excel", type="secondary", use_container_width=True):
                                excel_buffer = create_bivariate_excel_report(resultats_analyses, var_cible, ponderation, palette_name, selected_sheet)
                                st.download_button(
                                    label="üì• T√©l√©charger le rapport Excel",
                                    data=excel_buffer.getvalue(),
                                    file_name=f"analyses_bivariees_{var_cible}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        
                        with col2:
                            if st.button("üìÑ T√©l√©charger Word", type="secondary", use_container_width=True):
                                with st.spinner("G√©n√©ration du rapport Word..."):
                                    if enable_comments and commentator:
                                        word_doc = create_word_report_with_comments(
                                            df, numeric_vars, categorical_vars, 
                                            resultats_analyses, var_cible, 
                                            ponderation, palette_name, selected_sheet,
                                            commentator
                                        )
                                    else:
                                        word_doc = create_word_report(
                                            df, numeric_vars, categorical_vars, 
                                            resultats_analyses, var_cible, 
                                            ponderation, palette_name, selected_sheet
                                        )
                                    
                                    # Sauvegarder le document dans un buffer
                                    word_buffer = io.BytesIO()
                                    word_doc.save(word_buffer)
                                    word_buffer.seek(0)
                                    
                                    filename_suffix = "_commente" if enable_comments else ""
                                    st.download_button(
                                        label="üì• T√©l√©charger le rapport Word",
                                        data=word_buffer.getvalue(),
                                        file_name=f"rapport_analyses{filename_suffix}_{var_cible}_{datetime.now().strftime('%Y%m%d_%H%M')}.docx",
                                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                    )
        
        with tab4:
            st.markdown('<div class="sub-header">üì• Exports et t√©l√©chargements</div>', unsafe_allow_html=True)
            
            # Affichage de l'√©tat des commentaires
            if enable_comments and commentator:
                st.success("‚úÖ Commentaires automatiques activ√©s")
                if commentator.study_theme:
                    st.info(f"üéØ Th√®me: {commentator.study_theme[:50]}...")
                if commentator.reference_context:
                    st.info("üìÑ Document de r√©f√©rence charg√©")
            else:
                st.info("üìù Commentaires automatiques d√©sactiv√©s")
            
            st.info("üí° Les graphiques sont automatiquement sauvegard√©s en PNG dans les dossiers Sorties/")
            
            # Affichage de la palette utilis√©e
            st.subheader("üé® Palette utilis√©e")
            show_palette_preview(palette_name, selected_colors)
            
            # Statistiques descriptives
            st.subheader("üìä Exports des analyses")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**üìä Analyses univari√©es**")
                
                # Export Excel
                if st.button("üìä Excel univari√©", use_container_width=True):
                    with st.spinner("G√©n√©ration du rapport Excel..."):
                        # Cr√©er un fichier Excel avec plusieurs feuilles
                        excel_buffer = io.BytesIO()
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            
                            # Feuille des variables num√©riques
                            if numeric_vars:
                                stats_table = analyze_numeric_variables(df, numeric_vars, ponderation)
                                stats_table.to_excel(writer, sheet_name='Variables_numeriques', index=True)
                            
                            # Feuille des variables qualitatives
                            if categorical_vars:
                                all_freq_tables = {}
                                for var in categorical_vars:
                                    if ponderation is None:
                                        value_counts = df[var].value_counts()
                                        total = value_counts.sum()
                                    else:
                                        mask_valid = df[var].notna() & df[ponderation].notna()
                                        if mask_valid.sum() > 0:
                                            value_counts = df[mask_valid].groupby(var)[ponderation].sum().sort_values(ascending=False)
                                            total = value_counts.sum()
                                        else:
                                            continue
                                    
                                    freq_table = pd.DataFrame({
                                        'Effectif': value_counts,
                                        'Fr√©quence (%)': (value_counts / total * 100).round(2)
                                    })
                                    all_freq_tables[var] = freq_table
                                
                                # √âcrire chaque tableau sur une ligne diff√©rente
                                start_row = 0
                                for var_name, freq_table in all_freq_tables.items():
                                    freq_table.to_excel(writer, sheet_name='Variables_qualitatives', 
                                                      startrow=start_row, startcol=0)
                                    # Ajouter le nom de la variable
                                    worksheet = writer.sheets['Variables_qualitatives']
                                    worksheet.cell(row=start_row+1, column=1, value=f"Variable: {var_name}")
                                    start_row += len(freq_table) + 3
                            
                            # Feuille d'informations g√©n√©rales
                            info_df = pd.DataFrame({
                                'M√©trique': ['Nombre de lignes', 'Nombre de colonnes', 'Variables num√©riques', 
                                           'Variables qualitatives', 'Feuille Excel', 'Pond√©ration utilis√©e', 
                                           'Palette de couleurs', 'Commentaires automatiques', 'Date d\'analyse'],
                                'Valeur': [df.shape[0], df.shape[1], len(numeric_vars), len(categorical_vars),
                                         selected_sheet if selected_sheet else 'N/A (CSV)', 
                                         ponderation if ponderation else 'Aucune', palette_name,
                                         'Activ√©s' if enable_comments else 'D√©sactiv√©s',
                                         datetime.now().strftime('%Y-%m-%d %H:%M')]
                            })
                            info_df.to_excel(writer, sheet_name='Informations', index=False)
                        
                        st.download_button(
                            label="üì• T√©l√©charger Excel univari√©",
                            data=excel_buffer.getvalue(),
                            file_name=f"rapport_univarie_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key="download_excel_univarie"
                        )
                
                # Export Word
                if st.button("üìÑ Word univari√©", use_container_width=True):
                    with st.spinner("G√©n√©ration du rapport Word..."):
                        if enable_comments and commentator:
                            word_doc = create_word_report_with_comments(
                                df, numeric_vars, categorical_vars,
                                None, None,  # Pas d'analyses bivari√©es
                                ponderation, palette_name, selected_sheet,
                                commentator
                            )
                        else:
                            word_doc = create_word_report(
                                df, numeric_vars, categorical_vars,
                                None, None,  # Pas d'analyses bivari√©es
                                ponderation, palette_name, selected_sheet
                            )
                        
                        # Sauvegarder le document dans un buffer
                        word_buffer = io.BytesIO()
                        word_doc.save(word_buffer)
                        word_buffer.seek(0)
                        
                        filename_suffix = "_commente" if enable_comments else ""
                        st.download_button(
                            label="üì• T√©l√©charger Word univari√©",
                            data=word_buffer.getvalue(),
                            file_name=f"rapport_univarie{filename_suffix}_{datetime.now().strftime('%Y%m%d_%H%M')}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key="download_word_univarie"
                        )
            
            with col2:
                st.write("**üîó Analyses bivari√©es**")
                
                # V√©rifier si des analyses bivari√©es ont √©t√© effectu√©es
                data = st.session_state.analyses_data
                if data.get('resultats_bivariees') and data.get('var_cible'):
                    st.success("‚úÖ Analyses bivari√©es disponibles")
                    
                    # Export Excel bivari√©es
                    if st.button("üìä Excel bivari√©es", use_container_width=True):
                        excel_buffer = create_bivariate_excel_report(
                            data['resultats_bivariees'], 
                            data['var_cible'], 
                            ponderation, 
                            palette_name, 
                            selected_sheet
                        )
                        st.download_button(
                            label="üì• T√©l√©charger Excel bivari√©es",
                            data=excel_buffer.getvalue(),
                            file_name=f"analyses_bivariees_{data['var_cible']}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key="download_excel_bivariees"
                        )
                    
                    # Export Word bivari√©es
                    if st.button("üìÑ Word bivari√©es", use_container_width=True):
                        with st.spinner("G√©n√©ration du rapport Word bivari√©es..."):
                            if enable_comments and commentator:
                                word_doc = create_word_report_with_comments(
                                    df, numeric_vars, categorical_vars,
                                    data['resultats_bivariees'], 
                                    data['var_cible'],
                                    ponderation, palette_name, selected_sheet,
                                    commentator
                                )
                            else:
                                word_doc = create_word_report(
                                    df, numeric_vars, categorical_vars,
                                    data['resultats_bivariees'], 
                                    data['var_cible'],
                                    ponderation, palette_name, selected_sheet
                                )
                            
                            # Sauvegarder le document dans un buffer
                            word_buffer = io.BytesIO()
                            word_doc.save(word_buffer)
                            word_buffer.seek(0)
                            
                            filename_suffix = "_commente" if enable_comments else ""
                            st.download_button(
                                label="üì• T√©l√©charger Word bivari√©es",
                                data=word_buffer.getvalue(),
                                file_name=f"rapport_bivariees{filename_suffix}_{data['var_cible']}_{datetime.now().strftime('%Y%m%d_%H%M')}.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                key="download_word_bivariees"
                            )
                    
                    content_type = "comment√©" if enable_comments else "standard"
                    st.write(f"**Contenu des rapports bivari√©es ({content_type}) :**")
                    if enable_comments:
                        st.write("‚Ä¢ Synth√®se des relations significatives")
                        st.write("‚Ä¢ Interpr√©tations automatiques d√©taill√©es")
                        st.write("‚Ä¢ Insights contextuels adapt√©s")
                        st.write("‚Ä¢ Recommandations cibl√©es")
                    else:
                        st.write("‚Ä¢ Tableaux crois√©s et statistiques")
                        st.write("‚Ä¢ Tests statistiques complets")
                        st.write("‚Ä¢ Graphiques int√©gr√©s")
                    st.write("‚Ä¢ Synth√®se de toutes les analyses")
                else:
                    st.info("üí° Effectuez d'abord des analyses bivari√©es dans l'onglet correspondant.")
                    st.write("**Une fois les analyses effectu√©es :**")
                    st.write("‚Ä¢ Exports Excel et Word disponibles")
                    st.write("‚Ä¢ Tableaux crois√©s et statistiques")
                    st.write("‚Ä¢ Tous les tests statistiques")
                    st.write("‚Ä¢ Graphiques int√©gr√©s")
                    if enable_comments:
                        st.write("‚Ä¢ Commentaires automatiques")
            
            with col3:
                st.write("**üìÑ Rapport complet**")
                
                # Export Excel complet
                if st.button("üìä Excel complet", use_container_width=True):
                    with st.spinner("G√©n√©ration du rapport Excel complet..."):
                        # Cr√©er un fichier Excel avec toutes les analyses
                        excel_buffer = io.BytesIO()
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            
                            # Informations g√©n√©rales
                            info_df = pd.DataFrame({
                                'M√©trique': ['Nombre de lignes', 'Nombre de colonnes', 'Variables num√©riques', 
                                           'Variables qualitatives', 'Feuille Excel', 'Pond√©ration utilis√©e', 
                                           'Palette de couleurs', 'Commentaires automatiques', 'Analyses bivari√©es', 'Date d\'analyse'],
                                'Valeur': [df.shape[0], df.shape[1], len(numeric_vars), len(categorical_vars),
                                         selected_sheet if selected_sheet else 'N/A (CSV)', 
                                         ponderation if ponderation else 'Aucune', palette_name,
                                         'Activ√©s' if enable_comments else 'D√©sactiv√©s',
                                         'Oui' if data.get('resultats_bivariees') else 'Non',
                                         datetime.now().strftime('%Y-%m-%d %H:%M')]
                            })
                            info_df.to_excel(writer, sheet_name='00_Informations', index=False)
                            
                            # Variables num√©riques
                            if numeric_vars:
                                stats_table = analyze_numeric_variables(df, numeric_vars, ponderation)
                                stats_table.to_excel(writer, sheet_name='01_Var_numeriques', index=True)
                            
                            # Variables qualitatives
                            if categorical_vars:
                                start_row = 0
                                for var in categorical_vars:
                                    if ponderation is None:
                                        value_counts = df[var].value_counts()
                                        total = value_counts.sum()
                                    else:
                                        mask_valid = df[var].notna() & df[ponderation].notna()
                                        if mask_valid.sum() > 0:
                                            value_counts = df[mask_valid].groupby(var)[ponderation].sum().sort_values(ascending=False)
                                            total = value_counts.sum()
                                        else:
                                            continue
                                    
                                    freq_table = pd.DataFrame({
                                        'Effectif': value_counts,
                                        'Fr√©quence (%)': (value_counts / total * 100).round(2)
                                    })
                                    
                                    freq_table.to_excel(writer, sheet_name='02_Var_qualitatives', 
                                                      startrow=start_row, startcol=0)
                                    worksheet = writer.sheets['02_Var_qualitatives']
                                    worksheet.cell(row=start_row+1, column=1, value=f"Variable: {var}")
                                    start_row += len(freq_table) + 3
                            
                            # Analyses bivari√©es si disponibles
                            if data.get('resultats_bivariees'):
                                # Synth√®se bivari√©es
                                synthese_data = []
                                for var_name, resultats in data['resultats_bivariees'].items():
                                    synthese_data.append({
                                        'Variable': var_name,
                                        'Type d\'analyse': resultats['type_analyse'],
                                        'Observations': resultats['n_observations'],
                                        'Test principal': resultats.get('test_principal', 'N/A'),
                                        'P-value': resultats.get('p_value_principal', 'N/A'),
                                        'Significatif': resultats.get('significatif_principal', 'N/A')
                                    })
                                
                                synthese_df = pd.DataFrame(synthese_data)
                                synthese_df.to_excel(writer, sheet_name='03_Synthese_bivariees', index=False)
                        
                        st.download_button(
                            label="üì• T√©l√©charger Excel complet",
                            data=excel_buffer.getvalue(),
                            file_name=f"rapport_complet_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key="download_excel_complet"
                        )
                
                # Export Word complet
                if st.button("üìÑ Word complet", use_container_width=True):
                    with st.spinner("G√©n√©ration du rapport Word complet..."):
                        if enable_comments and commentator:
                            word_doc = create_word_report_with_comments(
                                df, numeric_vars, categorical_vars,
                                data.get('resultats_bivariees'), 
                                data.get('var_cible'),
                                ponderation, palette_name, selected_sheet,
                                commentator
                            )
                        else:
                            word_doc = create_word_report(
                                df, numeric_vars, categorical_vars,
                                data.get('resultats_bivariees'), 
                                data.get('var_cible'),
                                ponderation, palette_name, selected_sheet
                            )
                        
                        # Sauvegarder le document dans un buffer
                        word_buffer = io.BytesIO()
                        word_doc.save(word_buffer)
                        word_buffer.seek(0)
                        
                        filename_suffix = "_commente" if enable_comments else ""
                        st.download_button(
                            label="üì• T√©l√©charger Word complet",
                            data=word_buffer.getvalue(),
                            file_name=f"rapport_complet{filename_suffix}_{datetime.now().strftime('%Y%m%d_%H%M')}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key="download_word_complet_comments"
                        )
                
                content_type = "comment√©" if enable_comments else "standard"
                st.write(f"**Contenu du rapport complet ({content_type}) :**")
                if enable_comments:
                    st.write("‚Ä¢ Contexte de l'√©tude int√©gr√©")
                    st.write("‚Ä¢ Interpr√©tations automatiques d√©taill√©es")
                    st.write("‚Ä¢ Insights contextuels pour chaque analyse")
                    st.write("‚Ä¢ Recommandations cibl√©es")
                    st.write("‚Ä¢ Synth√®se des relations significatives")
                    st.write("‚Ä¢ Conclusion enrichie avec recommandations")
                else:
                    st.write("‚Ä¢ Informations g√©n√©rales")
                    st.write("‚Ä¢ Analyses univari√©es compl√®tes")
                    st.write("‚Ä¢ Analyses bivari√©es (si effectu√©es)")
                    st.write("‚Ä¢ Tests statistiques")
                    st.write("‚Ä¢ Conclusion g√©n√©rale")
                st.write("‚Ä¢ Tableaux de fr√©quences")
                st.write("‚Ä¢ Graphiques int√©gr√©s")
                st.write("‚Ä¢ Notes techniques")
            
            # Donn√©es filtr√©es
            st.subheader("üìã Export des donn√©es")
            if st.button("üì• T√©l√©charger les donn√©es (CSV)"):
                csv_buffer = io.StringIO()
                df.to_csv(csv_buffer, index=False)
                st.download_button(
                    label="üì• T√©l√©charger CSV",
                    data=csv_buffer.getvalue(),
                    file_name=f"donnees_exportees_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                    mime="text/csv"
                )
            
            # Informations sur les exports
            st.subheader("üìÅ Localisation des fichiers")
            st.info("""
            **Les fichiers sont automatiquement sauvegard√©s dans :**
            - üìä `Sorties/Stat_Univari√©es/` : Graphiques des analyses univari√©es (PNG)
            - üîó `Sorties/Stat_Bivari√©es/` : Graphiques des analyses bivari√©es (PNG)
            - üì• `Sorties/Exports/` : Rapports Excel et exports de donn√©es
            """)
            
            st.subheader("üí° Notes d'utilisation")
            st.info("""
            **Commentaires automatiques :**
            - Activez les commentaires dans la sidebar pour des rapports enrichis
            - D√©finissez un th√®me d'√©tude pour des insights contextuels
            - Chargez un document de r√©f√©rence pour plus de pertinence
            
            **Installation pour les rapports Word :**
            ```bash
            pip install python-docx
            ```
            Cette d√©pendance est n√©cessaire pour cr√©er les documents Word avec tableaux et images.
            """)
    
    else:
        # Page d'accueil si aucun fichier n'est charg√© ou aucune feuille s√©lectionn√©e
        if uploaded_file is not None and df is None:
            st.warning("‚ö†Ô∏è Veuillez s√©lectionner une feuille Excel pour continuer.")
        else:
            
                st.subheader ("üöÄ Bienvenue dans l'Analyseur Statistique Pro!")
                st.write("Cet outil vous permet d'effectuer facilement des analyses statistiques compl√®tes sur vos donn√©es")
                
                st.subheader ("üÜï Nouveaut√©s - Commentaires automatiques")
                
                st.write("‚Ä¢üí¨ Interpr√©tations automatiques- Commentaires intelligents pour chaque analyse")
                st.write("‚Ä¢üéØ Contextualisation- Adaptation selon le th√®me de votre √©tude")
                st.write("‚Ä¢üìÑ Document de r√©f√©rence- Upload de contexte pour plus de pertinence")
                st.write("‚Ä¢üìã Recommandations- Suggestions d'actions bas√©es sur les r√©sultats")
                
                
                st.subheader ("üìã Fonctionnalit√©s principales")
                
                st.write("‚Ä¢üìä Analyses univari√©es- Statistiques descriptives et graphiques")
                st.write("‚Ä¢üîó Analyses bivari√©es- Tableaux crois√©s et tests statistiques")
                st.write("‚Ä¢‚öñÔ∏è Analyses pond√©r√©es- Support de la pond√©ration")
                st.write("‚Ä¢üé® Palettes personnalisables- 7 palettes de couleurs au choix")
                st.write("‚Ä¢üìà Graphiques interactifs- Visualisations avec streamlit-echarts")
                st.write("‚Ä¢üì• Exports automatiques- Excel, CSV, images PNG")
                st.write("‚Ä¢üìÑ Rapports Word- Documents professionnels avec tableaux et graphiques")
                st.write("‚Ä¢üìã Support multi-feuilles- S√©lection de feuilles Excel")
                
                
                st.subheader ("üé® Logique des graphiques :")
                
                st.write("‚â§ ‚Ä¢3 modalit√©s :Graphiques en secteurs (alternance disque/anneau)")
                st.write("> ‚Ä¢3 modalit√©s :Graphiques en barres (alternance vertical/horizontal)")
                
                
                st.subheader ("üîß Pour commencer :")
                st.write("‚Ä¢Configurez les commentairesdans la sidebar (optionnel mais recommand√©)")
                st.write("‚Ä¢Chargez votre fichier de donn√©es (CSV ou Excel)")
                st.write("‚Ä¢Si c'est un fichier Excel, s√©lectionnez la feuille √† analyser")
                st.write("‚Ä¢Choisissez votre palette de couleurs pr√©f√©r√©e")
                st.write("‚Ä¢Configurez √©ventuellement une variable de pond√©ration")
                st.write("‚Ä¢Explorez vos donn√©es dans l'onglet Aper√ßu")
                st.write("‚Ä¢Lancez vos analyses dans les onglets d√©di√©s")
                
                st.subheader ("üìã Formats support√©s :")
                
                st.write("‚Ä¢Entr√©e :CSV (d√©tection automatique du s√©parateur), Excel (.xlsx, .xls) multi-feuilles")
                st.write("‚Ä¢Documents de r√©f√©rence :TXT, DOCX")
                st.write("‚Ä¢Sortie :Excel (.xlsx), Word (.docx), Images PNG, CSV")
                
                
                st.subheader ("üí° Conseils d'utilisation :")
                
                st.write("‚Ä¢Activez les commentaires automatiques pour des rapports plus riches")
                st.write("‚Ä¢D√©finissez un th√®me d'√©tude pr√©cis pour des insights contextuels")
                st.write("‚Ä¢Chargez un document de r√©f√©rence pour personnaliser les commentaires")
                st.write("‚Ä¢Utilisez la pond√©ration pour des analyses plus pr√©cises")
                

if __name__ == "__main__":
    main()